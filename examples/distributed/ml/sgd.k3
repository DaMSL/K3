include "Annotation/Collection.k3"
include "Annotation/Vector.k3"
include "Annotation/Set.k3"
include "Core/Builtins.k3"
include "Core/CppBuiltins.k3"
include "Core/MachineMessaging.k3"
include "Core/Barrier.k3"
include "Annotation/Map.k3"

declare master: address = 127.0.0.1:40000
declare peers_ready: mut int = 0
declare iterations_remaining: mut int = 10
declare dimensionality: int = 2
declare dataFiles: collection {path: string} @Collection

declare start_ms: mut int
declare end_ms: mut int
declare elapsed_ms: mut int
declare time_stats: mut {iter_count: int, iter_time_sum: real}
declare iter_start: mut int
declare iter_end: mut int

trigger hello : () = \_ -> (
  ((ready, master) <- ()) @OnCounter(id=[# hello_done], eq=[$ peers.size()], reset=[$ false], profile=[$ false])
)

trigger start_profiler : () = \_ -> (
  ((tcmallocStart ()); (jemallocStart ()); (pcmStart ())) @IfMachineMaster
)

// Hyperparameters
declare step_size: mut real = 0.1
declare lambda: mut real = 0.1

// Master
declare aggregates: mut {count: int, sum: collection {elem: real} @Vector }

// All Nodes:
declare parameters: mut collection {elem: real} @Vector
declare data: collection { elem: collection {elem: real}@Vector, class_label: real } @ { Collection }

// SVM Loss at 1 point.
declare svm_loss : collection {elem: real} @Vector  -> real -> real = \x -> \y -> (
  let q = 1 - (y * (parameters.dot x))
  in (lambda * (parameters.dot parameters) + (if q < 0 then 0 else q))
)

// SVM Loss averaged over data
declare svm_loss_avg : () -> real = \_ -> (
  let stats =
    data.fold
      (\acc -> \d ->
        {count: acc.count +1, sum: acc.sum + (svm_loss d.elem d.class_label)}
      )
      {count:0, sum:0.0}
  in stats.sum / stats.count
)

// Update parameters based on a single point
declare update_parameters: collection {elem: real} @Vector  -> real -> () = \point -> \class_label -> (
  let flag = class_label * (parameters.dot point) in
  let update =
    if flag > 1
    then parameters.scalarMult lambda
    else (parameters.scalarMult lambda).sub (point.scalarMult class_label)
  in
  parameters.inPlaceSub (update.scalarMult step_size)
)

// Print results
declare print_results : () -> () = \_ -> (
  let avg_iter_time = (time_stats.iter_time_sum / time_stats.iter_count) in
  end_ms = now_int ();
  elapsed_ms = end_ms - start_ms;
  print ("Elapsed: " ++ (itos elapsed_ms));
  print ("Avg time per iteration: " ++ (rtos avg_iter_time))
)

// Run SGD on local dataset.
// 0) Receive updated parameters from master
// 1) Update local parameters once per data point (randomly ordered/drawn)
// 2) Send local parameters to master for aggregation
trigger local_sgd : collection {elem: real} @Vector  = \new_params -> (
  (parameters = new_params);
  (data.iterate (\d -> update_parameters d.elem d.class_label));
  (aggregate, master) <- parameters;
  step_size = 0.95 * step_size
)

// Barrier: Stash local aggregates until all peers are finished. Then maximize.
trigger aggregate : collection {elem: real} @Vector  = \local_params -> (
  let new_sum = local_params.add (aggregates.sum) in
  let new_count = 1 + aggregates.count
  in (
    aggregates = {count: new_count, sum: new_sum};
    if new_count == (peers.size ())
    then (maximize,master) <- ()
    else ()
  )
)


// TODO: more in place operations on the parameters
// consider inPlaceScalarMult
// Average local parameters from each peer, then start a new iteration.
trigger maximize : () = \_ -> (
  parameters = (aggregates.sum).scalarMult (1.0 / aggregates.count);
  print "Loss:";
  print (rtos (svm_loss_avg ()));
  aggregates = {count:0, sum: (zeroVector dimensionality)};
  iter_end = now_int();
  time_stats = {iter_count: time_stats.iter_count + 1, iter_time_sum: time_stats.iter_time_sum + (iter_end - iter_start)};
  iterations_remaining = iterations_remaining - 1;
  if iterations_remaining == 0
  then (print_results (); peers.iterate (\p -> (shutdown, p.addr) <- ()))
  else (
    iter_start = now_int ();
    peers.iterate (\p -> (local_sgd, p.addr) <- parameters)
  )
)

// TODO: random instead of zero
// Randomly initialize parameters, and send them to each peer.
trigger start : () = \_ -> (
  aggregates = {count:0, sum: zeroVector dimensionality};
  start_ms = now_int ();
  parameters = zeroVector dimensionality;
  iter_start = now_int ();
  peers.iterate (\p -> (local_sgd, p.addr) <- parameters)
)

trigger ready : () = \_ -> (
  (peers_ready = peers_ready + 1);
  (if peers_ready == (peers.size ())
   then ((peers.iterate (\p -> (start_profiler, p.addr) <- () )); (start, master) <- ())
   else ()
  )
)

trigger shutdown: () = \_ -> (((tcmallocStop ()); (jemallocStop ()); (pcmStop ())) @IfMachineMaster; haltEngine ())

trigger load_all : () = \_ -> (
  dimensionality = dimensionality - 1; // Hack that enables k_means/sgd to share the same dataset/YAML config
  dataFiles.iterate (\f -> loadVectorLabel dimensionality f.path data);
  ( peers.iterate (\p -> (hello, p.addr) <- ()) )
)

source s1 : () = value ()
feed s1 |> load_all
