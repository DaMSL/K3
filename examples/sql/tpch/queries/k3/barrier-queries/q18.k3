include "tpch/benchmark.k3"

/**********************
* SQL query
***********************
select top 100
        c_name,
        c_custkey,
        o_orderkey,
        o_orderdate,
        o_totalprice,
        sum(l_quantity)
from
        customer,
        orders,
        lineitem
where
        o_orderkey in (
                select
                        l_orderkey
                from
                        lineitem
                group by
                        l_orderkey having
                                sum(l_quantity) > 300
        )
        and c_custkey = o_custkey
        and o_orderkey = l_orderkey
group by
        c_name,
        c_custkey,
        o_orderkey,
        o_orderdate,
        o_totalprice
order by
        o_totalprice desc,
        o_orderdate
****************************
* Plan:
* group by
*   join customer
*     join orders
*          (filter . group lineitem)
****************************/

declare lineitem : mut lineitem_bag
declare customer : mut customer_bag
declare orders   : mut orders_bag

// Final result.
typedef loc_q_by_ncodt_r   = { key: {nm:string, ck:int, ok:int, od:string, tp:real}, value: real}
typedef loc_q_by_ncodt_map = collection loc_q_by_ncodt_r @Map

declare q18_peer_result : loc_q_by_ncodt_map
declare results : collection {name: string, custkey: int, orderkey: int, orderdate:string, totalprice: real, sum: real} @Collection


// Q18 intermediates.
typedef o_cdt_by_ok_r = {key : int, value : { o_custkey    : int
                                            , o_orderdate  : string
                                            , o_totalprice : real}}

typedef lo_q_by_odt_r     = {key : {ok: int, od: string, tp: real}, value : real}
typedef lo_odtq_by_ck_r   = {key :int, value : collection lo_q_by_odt_r @Map}
typedef lo_odtq_by_ck_map = collection lo_odtq_by_ck_r @Map

declare master : address

declare lo_odtq_by_ck  : lo_odtq_by_ck_map
declare loc_q_by_ncodt : mut loc_q_by_ncodt_map

declare merge_q_by_odt_r : lo_q_by_odt_r -> lo_q_by_odt_r -> lo_q_by_odt_r
  = \a -> \b -> {key: a.key, value: a.value + b.value}

declare merge_odtq_by_ck_r : lo_odtq_by_ck_r -> lo_odtq_by_ck_r -> lo_odtq_by_ck_r
  = \a -> \b -> {key: a.key, value: a.value.fold (\acc -> \r -> ((acc.insert_with r merge_q_by_odt_r); acc)) b.value}

declare merge_q_by_ncodt_r : loc_q_by_ncodt_r -> loc_q_by_ncodt_r -> loc_q_by_ncodt_r
  = \a -> \b -> {key: a.key, value: a.value + b.value}

trigger lineitem_having : () = \_ -> (
  (ignore (lineitem.groupBy (\li -> li.l_orderkey)
                            (\acc -> \li -> acc + li.l_quantity)
                            0.0)
  ) @DistributedGroupBy(
      lbl         = [# li_having],
      clear_expr  = [$ lineitem = empty lineitem_r @Collection ],
      peer_next   = [$ (\result -> (
                          print "LI shuffle done." ;
                          li_having_result = result.filter (\okq -> okq.value > 300)
                        )) ],
      next        = [$ (print "LI shuffle all nodes finished"; (lineitem_orders, me) <- ()) ],
      merge       = [$ (\a -> \b -> a + b)],
      coordinator = [$ master],
      nodes       = [$ peers],
      masters     = [$ masters ],
      masters_map = [$ peer_masters ],
      profile     = [$ true] )
)

// Since lineitem is already partitioned by orderkey, we can implement the
// join as a distributed group-by on orders, with probes and intermediate
// construction occurring in the merge trigger.
trigger lineitem_orders : () = \_ -> (
  (ignore (orders.groupBy (\o -> o.o_orderkey)
                          (\_ -> \o -> { o_custkey    : o.o_custkey
                                       , o_orderdate  : o.o_orderdate
                                       , o_totalprice : o.o_totalprice })
                          {o_custkey:0, o_orderdate:"", o_totalprice:0.0})
  ) @DistributedGroupByGeneric(
      lbl         = [# lo ],
      clear_expr  = [$ orders = empty orders_r @Collection ],
      peer_next   = [$ print "LI-OR shuffle done." ],
      next        = [$ (lineitem_orders_customer, me) <- () ],
      merge       = [$ (\o ->
                          case li_having_result.lookup {key: o.key, value: 0.0} of
                          {Some li -> lo_odtq_by_ck.insert_with
                                        {key: o.value.o_custkey
                                        , value: {| key: {ok:int, od:string, tp:real}, value: real
                                                  | { key: { ok: o.key
                                                           , od: o.value.o_orderdate
                                                           , tp: o.value.o_totalprice }
                                                    , value: li.value}
                                                  |} @Map
                                        }
                                        merge_odtq_by_ck_r
                          }
                          {None -> ()})],
      coordinator = [$ master],
      nodes       = [$ peers],
      masters     = [$ masters ],
      masters_map = [$ peer_masters ],
      profile     = [$ true] )
)

trigger lineitem_orders_customer : () = \_ -> (
  ( () @:NoPipeline )
    @JoinSelector(
          lbl       = [# loc ]
        , lhs_ht_id = [# loc_lhs_ht ]
        , rhs_ht_id = [# loc_rhs_ht ]

        , lhs_sample_query     = [$ lo_odtq_by_ck.sample (\acc -> \r ->
                                                            ((acc.insert_with {key: r.key, value: 1}
                                                              (\old -> \new -> {key: old.key, value: old.value + new.value}));
                                                            acc))
                                                         (empty {key: int, value: int} @Map)
                                                         (lo_odtq_by_ck.size () / sample_factor)
                                 ]

        , rhs_sample_query     = [$ empty {key: int, value: int} @Map ]
        , frequency_threshold  = [$ 1000.0 ]

        , lhs_query = [$ lo_odtq_by_ck]
        , rhs_query = [$ (customer.groupBy (\c -> c.c_custkey)
                                           (\_ -> \c -> c.c_name)
                                           "")
                                  .fold    (\acc -> \c -> ((acc.insert c); acc))
                                           (empty {key: int, value: string} @Map)
                      ]

      , join_key_ty          = [: int ]
      , lhs_ht_ty            = [: {key: int, value: collection {key : {ok: int, od: string, tp: real}, value : real} @Map} ]
      , rhs_ht_ty            = [: {key: int, value: string} ]

      , lhs_probe            = [$ (\lht -> \out -> \r ->
                                    case lht.lookup {key: r.key, value: empty {key : {ok: int, od: string, tp: real}, value : real} @Map} of
                                    { Some l ->
                                      l.value.iterate (\kv ->
                                          loc_q_by_ncodt.insert_with
                                               { key: { nm: r.value, ck: r.key, ok: kv.key.ok, od: kv.key.od, tp: kv.key.tp }
                                               , value: kv.value }
                                               merge_q_by_ncodt_r )
                                    }
                                    { None   -> () }
                                  )
                               ]

      , rhs_probe            = [$ (\rht -> \out -> \l ->
                                    case rht.lookup {key: l.key, value: ""} of
                                    { Some r ->
                                      l.value.iterate (\kv ->
                                          loc_q_by_ncodt.insert_with
                                               { key: { nm: r.value, ck: r.key, ok: kv.key.ok, od: kv.key.od, tp: kv.key.tp }
                                               , value: kv.value }
                                               merge_q_by_ncodt_r )
                                    }
                                    { None   -> () }
                                  )
                               ]

      , lhs_insert_with      = [$ (\old -> \new -> {key: old.key, value:
                                    (new.value.fold
                                      (\acc -> \kv ->
                                        ((acc.insert_with
                                              {key:kv.key, value:kv.value}
                                              (\old2 -> \new2 -> {key:old2.key, value: old2.value + new2.value}));
                                          acc))
                                      old.value)}) ]

      , rhs_insert_with      = [$ (\_ -> \new -> new) ]

      , has_outputs          = [$ (\_ -> false) ]
      , empty_out_buffer     = [$ () ]


      , lhs_pipeline_next    = [$ (\_ -> ()) ]
      , rhs_pipeline_next    = [$ (\_ -> ())]

      , lhs_clear_expr       = [$ (\_ -> loc_lhs_ht = empty {key: int, value: collection {key : {ok: int, od: string, tp: real}, value : real} @Map} @Map) ]
      , rhs_clear_expr       = [$ (\_ -> loc_rhs_ht = empty {key: int, value: string} @Map) ]

      , peer_next            = [$ ( print "LI-OR-CS join finished customer probe." );
                                  ( (ignore loc_q_by_ncodt)
                                      @PartitionShuffleWithMissing(
                                        lbl = [# loc]
                                      , dest_trg = [$ loc_aggregate]
                                      , nodes = [$ peers]
                                      , send_extra_fn = [$ \x -> x]
                                      , send_ty = [: loc_q_by_ncodt_map]
                                      )

                                  );
                                  loc_q_by_ncodt = empty { key: {nm:string, ck:int, ok:int, od:string, tp:real}, value: real} @Map
                               ]

      , next                 = [$ print "LI-OR-CS join all nodes finished." ]
      , coordinator          = [$ master]
      , nodes                = [$ peers]
      , masters              = [$ masters ]
      , masters_map          = [$ peer_masters ]
      , profile              = [$ false]
    )
)

trigger loc_aggregate : loc_q_by_ncodt_map = \vals -> (
  (vals.iterate (\kv -> q18_peer_result.insert_with kv merge_q_by_ncodt_r));
  ( ( print "Query 18 done." ) ;
    ( (() @:Result) @TPCHBenchmarkWithoutMaster )
  ) @OnCounter(id=[# loc_aggregate_done], eq=[$ peers.size()], reset=[$ false], profile=[$ false])
)

trigger start : () = \_ -> (() @:Start) @TPCHBenchmarkWithoutMaster(
  nodes                = [$ peers ],
  loadExpr             = [$ ( // Read line counts for each data file
                              lineitemLineCountFiles.iterate (\e -> lineitemRows = lineitemRows + (lineCountFile e.path));
                              ordersLineCountFiles.iterate   (\e -> ordersRows = ordersRows + (lineCountFile e.path));
                              customerLineCountFiles.iterate (\e -> customerRows = customerRows + (lineCountFile e.path));

			      print ("Lineitem rows: " ++ (itos lineitemRows));
			      print ("Orders rows: " ++ (itos ordersRows));
			      print ("Customer rows: " ++ (itos customerRows));

                              // Load data using the fixed size loaders which resize the container before loading
			      lineitemFiles.iterate (\e -> lineitemLoaderPFixedSize e.path lineitem lineitemRows);
                              ordersFiles.iterate   (\e -> ordersLoaderPFixedSize   e.path orders ordersRows);
                              customerFiles.iterate (\e -> customerLoaderPFixedSize e.path customer customerRows)
                            ) ],
  preLoadExpr          = [$ ()],
  preReadyExpr         = [$ ()],
  onReadyExpr          = [$ (lineitem_having, me) <- ()],
  finishArgT           = [: ()],
  preTestFinishExpr    = [$ (\_ -> ())],
  preFinishExpr        = [$ (q18_peer_result.iterate(\r ->
                              results.insert { name: r.key.nm, custkey: r.key.ck, orderkey: r.key.ok
                                             , orderdate: r.key.od, totalprice: r.key.tp, sum: r.value} )
                            ); (
                            () @GatherResultsAsCSV(
                                    query_cl = [* [% ci: [# results], csink: [$ results_sink]] ]
                                  , nodes    = [$ peers]
                                  , next     = [$ peers.iterate (\p -> (shutdown, p.addr) <- ()) ])
                            )
                         ],
  preShutdownExpr      = [$ () ],
  finishAsShutdownExpr = [$ false]
)

sink results_sink : {name: string, custkey: int, orderkey: int, orderdate:string, totalprice: real, sum: real} = file "results.csv" csv
source rows : () = value ()
feed rows |> start
