include "Annotation/Collection.k3"
include "Annotation/BulkFlatCollection.k3"
include "Annotation/Map.k3"
include "Core/Builtins.k3"
include "Distributed/SQLTransformers.k3"
include "tpch/schema.k3"
include "tpch/loader.k3"

// Force generation of _BFC class (Codegen Bug)
declare dummy: collection lineitem_r @BulkFlatCollection
declare lineitem: lineitem_elem_bag

declare master: address
declare workers: mut collection {addr: address} @Collection
declare local_workers: mut collection {addr: address} @Collection

// TODO(jbw) find a home for index_by_hash
declare index_by_hash : forall a. a -> int = (\s -> (
  let n = workers.size () in
  let h = (hash s) in
    ((h % n) + n) % n
))

typedef q1_agg = { sum_qty: real, sum_base_price: real, sum_disc_price: real, sum_charge: real
                 , avg_qty_sum : real, avg_price_sum : real, avg_disc_sum : real, count_order : int }

typedef q1_result_r = { l_returnflag   : string
                      , l_linestatus   : string
                      , sum_qty        : real
                      , sum_base_price : real
                      , sum_disc_price : real
                      , sum_charge     : real
                      , avg_qty        : real
                      , avg_price      : real
                      , avg_disc       : real
                      , count_order    : int }

declare result: mut collection {key: (string, string), value: q1_agg} @Collection

declare init_agg    : q1_agg
declare accum_agg : q1_agg -> {elem: lineitem_r} -> q1_agg = \acc -> \r ->
  { sum_qty        : acc.sum_qty        + r.elem.l_quantity
  , sum_base_price : acc.sum_base_price + r.elem.l_extendedprice
  , sum_disc_price : acc.sum_disc_price + (r.elem.l_extendedprice * (1 - r.elem.l_discount))
  , sum_charge     : acc.sum_charge     + (r.elem.l_extendedprice * (1 - r.elem.l_discount) * (1 + r.elem.l_tax))
  , avg_qty_sum    : acc.avg_qty_sum    + r.elem.l_quantity
  , avg_price_sum  : acc.avg_price_sum  + r.elem.l_extendedprice
  , avg_disc_sum   : acc.avg_disc_sum   + r.elem.l_discount
  , count_order    : acc.count_order    + 1
  }

declare merge_agg : q1_agg -> q1_agg -> q1_agg = \a -> \b -> (
  { sum_qty        : a.sum_qty        + b.sum_qty
  , sum_base_price : a.sum_base_price + b.sum_base_price
  , sum_disc_price : a.sum_disc_price + b.sum_disc_price
  , sum_charge     : a.sum_charge     + b.sum_charge
  , avg_qty_sum    : a.avg_qty_sum    + b.avg_qty_sum
  , avg_price_sum  : a.avg_price_sum  + b.avg_price_sum
  , avg_disc_sum   : a.avg_disc_sum   + b.avg_disc_sum
  , count_order    : a.count_order    + b.count_order
  }
)

// Timing
declare start: mut int = 0
declare end: mut int = 0

// Initialize workers and local_workers to exclude machine_masters from performing work
trigger init: () = \_ -> (
  workers = peers.filter (\p -> peer_masters.lookup {key: p.addr, value: p.addr} (\_ -> error ()) (\kv -> kv.key != kv.value));
  local_workers = local_peers.filter (\p -> peer_masters.lookup {key: p.addr, value: p.addr} (\_ -> error ()) (\kv -> kv.key != kv.value));
  (ready, master) <- ()
)

// Initial barrier
trigger ready: () = \_ -> (
  start = now_int();
  peers.iterate (\p -> (t, p.addr) <- ())
) @Barrier(lbl=[# ready], count=[$ peers.size() ])

declare lineitem_path: string = "/local/data/tpch10g/lineitem_bfcs"

// Local Trigger
trigger t: () = \_ -> (
  result = ((((lineitem @:BaseTable "lineitem_path")
             .filter
               (\e -> e.elem.l_shipdate <= 19980902))
             .group_by
               (\e -> (e.elem.l_returnflag, e.elem.l_linestatus) )
               accum_agg
               init_agg) @:Stream);
  (done, master) <- ()
) @DistributedGroupBy2(lbl=[# gb1], merge=[$ merge_agg ])

declare lineitem_e: mut collection {elem: lineitem_r} @Collection
declare result2: mut collection {elem: int} @Collection

trigger t2: () = \_ -> (
  result2 = ((((lineitem @:BaseTable "lineitem_path")
             .filter
               (\e -> e.elem.l_shipdate <= 19980902)) @:Stream)
             .equijoin
               ((lineitem @:BaseTable "lineitem_path") @:Stream)
               (\e -> e.elem.l_orderkey)
               (\e -> e.elem.l_orderkey)
               (\_ -> \_ -> 1));
  (done, master) <- ()
) @DistributedHashJoin2(lbl=[# join1])

// Final barrier
trigger done: () = \_ -> (
  end = now_int ();
  print ("Time: " ++ (itos (end - start)));
  print ("Collecting results...");
  peers.iterate (\p -> (push_results, p.addr) <- () )
) @Barrier(lbl=[# done], count=[$ workers.size() ])

// Send results to master
trigger push_results: () = \_ -> (
  (gather_results, master) <-  result
)

// Gather results at master
trigger gather_results: collection {key: (string, string), value: q1_agg} @Collection = \c -> (
  c.iterate (\r ->
    bind r.key as (rflag, linestat) in
     (results, me) <- ( rflag
                      , linestat
                      , r.value.sum_qty
                      , r.value.sum_base_price
                      , r.value.sum_disc_price
                      , r.value.sum_charge
                      , r.value.avg_qty_sum   / r.value.count_order
                      , r.value.avg_price_sum / r.value.count_order
                      , r.value.avg_disc_sum  / r.value.count_order
                      , r.value.count_order
                      )
  );
  (peers.iterate (\p -> (stop, p.addr) <- ())) @Barrier(lbl=[# results], count=[$ peers.size() ])
)

// Terminate the program
trigger stop: () = \_ -> (
  haltEngine()
)

sink results: (string, string, real, real, real, real, real, real, real, int)  = file "results.csv" text psv

source s1 : () = value ()
feed s1 |> init
