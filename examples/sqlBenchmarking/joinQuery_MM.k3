/*
 * joinQuery_MM.k3
 *
 * Created by Kartik Thapar on 05/20/2014 at 20:14:44
 * Copyright (c) 2014 Kartik Thapar. All rights reserved.
 *
 */

include "Annotation/Collection.k3"
include "Core/Builtins.k3"
include "Core/Time.k3"

 /*
  * 1. Implement the join algorithm using thetaJoin implemented before.
  * 2. Implement GROUP BY for UV.sourceIP and get totalRevenue.
  * 3. Implement ORDER BY DESC LIMIT 1 by retrieving the row with max totalRevenue with row.Id that comes first.
  *    Send it to master and then select the max totalRevenue with row.Id that comes first.
  */

/* DATASETS */

/*
 * Datasets only hold columns that are used in the final output set computation.
 * Columns utilized are: UV.SourceIP, UV.DestURL, UV.VisitDate, UV.AdRevenue, R.PageRank, R.PageURL.
 */

declare sTable: collection {Id: int, PageURL: string, PageRank: int} @ {Collection}
declare tTable: collection {Id: int, SourceIP: string, DestURL: string, VisitDate: {y: int, m: int, d: int}, AdRevenue: real} @ {Collection}

declare sNumRows: mut int = 0
declare tNumRows: mut int = 0
declare totalRows: mut int
declare rowCounter: mut int = 0

declare thresholdDate: mut {y: int, m: int, d: int}

/* MASTER */

declare master: mut address

/* MAPPER */

declare sMappers: mut collection {Address: address, Id: int} @ {Collection}
declare tMappers: mut collection {Address: address, Id: int} @ {Collection}

declare sNumMappers: mut int
declare tNumMappers: mut int
declare sCurrentMapperSize: mut int = 0
declare tCurrentMapperSize: mut int = 0

declare currentMapperSize: mut int = 0
declare sMapperOutput: collection {RegionId: int, Output: collection {Id: int, PageURL: string, PageRank: int} @ {Collection}} @ {Collection}
declare tMapperOutput: collection {RegionId: int, Output: collection {Id: int, SourceIP: string, DestURL: string, VisitDate: {y: int, m: int, d: int}, AdRevenue: real} @ {Collection}} @ {Collection}

declare _randomRow: mut int = 0
declare _randomColumn: mut int = 0

/* REDUCER */

/* Number of Reducers is equal to the total of Regions in the grid */
declare reducers: mut collection {Address: address, Id: int} @ {Collection}

declare sTuples: collection {Id: int, PageURL: string, PageRank: int} @ {Collection}
declare tTuples: collection {Id: int, SourceIP: string, DestURL: string, VisitDate: {y: int, m: int, d: int}, AdRevenue: real} @ {Collection}

/* REGIONS */

declare maxS: mut int
declare maxT: mut int
declare rowLookupTable: mut collection {Row: int, Regions: mut collection {RegionId: int} @ {Collection}} @ {Collection}
declare columnLookupTable: mut collection {Column: int, Regions: collection {RegionId: int} @ {Collection}} @ {Collection}

/* OUTPUT */

declare output: collection {SourceIP: string, TotalRevenue: real, AvgPageRank: real} @ {Collection}

/* PHASE 1: PRE-PROCESS 1 - Process Table Rows */

trigger preProcessTableRows: ({fromS: bool, sRow: option {PageURL: string, PageRank: int, AvgDuration: int}, tRow: option {SourceIP: string, DestURL: string, VisitDate: {y: int, m: int, d: int}, AdRevenue: real, UserAgent: string, CountryCode: string, LanguageCode: string, SearchWord: string, Duration: int}}) = \tableRow -> (
    rowCounter = rowCounter + 1;
    if tableRow.fromS then
        sNumRows = sNumRows + 1;
        case tableRow.sRow of 
        {Some x -> sTable.insert {Id: sNumRows, PageURL: x.PageURL, PageRank: x.PageRank}}
        {None -> ()}
    else
        tNumRows = tNumRows + 1;
        case tableRow.tRow of
        {Some x -> tTable.insert {Id: tNumRows, SourceIP: x.SourceIP, DestURL: x.DestURL, VisitDate: x.VisitDate, AdRevenue: x.AdRevenue}}
        {None -> ()};

    /* If all the rows have been processed, process regions. */
    if rowCounter == totalRows then (preProcessRegions, me) <- ()
    else ()

)

/* PHASE 1: PRE-PROCESS 2 - Process Regions*/

declare _tmpRegions: mut collection {RegionId: int} @ {Collection}

declare getSRegions: immut (collection {RegionId: int} @ {Collection} -> int -> collection {RegionId: int} @ {Collection}) = fun tmpRegionsX -> fun rowNumber -> (
    (getSRegionsWorker tmpRegionsX ((rowNumber - 1)/maxS * tNumRows/maxT) (tNumRows/maxT))
)

declare getSRegionsWorker: immut (collection {RegionId: int} @ {Collection} -> int -> int -> collection {RegionId: int} @ {Collection}) = fun tmpRegionsX -> fun regionNumber -> fun count -> (
    /* 
     * tmpRegionsX is just the carrier collection for RegionIds; count refers to max number of regions in a row which are added to the regionNumber iteratively.
     * Until count > 0, keep inserting regionNumber + count as a RegionId 
     */
    if count > 0 then
        tmpRegionsX.insert {RegionId: regionNumber + count};
        (getSRegionsWorker tmpRegionsX regionNumber (count - 1))
    else
        tmpRegionsX
)

declare getTRegions: immut (collection {RegionId: int} @ {Collection} -> int -> collection {RegionId: int} @ {Collection}) = fun tmpRegionsX -> fun columnNumber -> (
    (getTRegionsWorker tmpRegionsX ((columnNumber - 1)/maxT + 1) 0)
)

declare getTRegionsWorker: immut (collection {RegionId: int} @ {Collection} -> int -> int -> collection {RegionId: int} @ {Collection}) = fun tmpRegionsX -> fun regionNumber -> fun count -> (
    /* 
     * count is a multiplier to the max number of regions in a row;
     * At every point we check if the regionNumber + thisvalue is greater than total number of regions possible and add to region list if not.
     */
    if (regionNumber + count*(tNumRows/maxT)) <= (sNumRows/maxS * tNumRows/maxT) then
        tmpRegionsX.insert {RegionId: regionNumber + count*(tNumRows/maxT)};
        (getTRegionsWorker tmpRegionsX regionNumber (count + 1))
    else
        tmpRegionsX
)

declare preProcessRegionsWorker: mut (int -> string -> ()) = fun numberOfRows -> fun tableName -> (
    /* 
     * Process every single row from the last row to the first row; numberOfRows is just the max row count; but essentially the row number.
     * Create an empty collection always (by searching for a RegionId that does not exist - hack for clearing a list).
     * Find regions and then update them for every row/column.
     */
    if numberOfRows > 0 then
        if tableName == "S" then
            _tmpRegions = _tmpRegions.filter (\region -> region.RegionId == -1);
            _tmpRegions = (getSRegions _tmpRegions numberOfRows);
            rowLookupTable.insert {Row: numberOfRows, Regions: _tmpRegions};
            (preProcessRegionsWorker (numberOfRows - 1) "S")
        else
            _tmpRegions = _tmpRegions.filter (\region -> region.RegionId == -1);
            _tmpRegions = (getTRegions _tmpRegions numberOfRows);
            columnLookupTable.insert {Column: numberOfRows, Regions: _tmpRegions};
            (preProcessRegionsWorker (numberOfRows - 1) "T")
    else ()
)

trigger preProcessRegions: () = \_ -> (
    (preProcessRegionsWorker sNumRows "S");
    (preProcessRegionsWorker tNumRows "T");
    (arrangeMap, me) <- ()
) 

/* PHASE 2: MAP */

declare getRandom: immut (string -> int) = fun tableName -> (
    if tableName == "S" then (random (sNumRows - 1) + 1)
    else (random (tNumRows - 1) + 1)
)

declare getMapperSize: immut (int -> string -> int) = fun mapperId -> fun tableName -> (
    /*
     * If r == 0 => equal division
     * If mapperId <= r => some r mappers will get the extra 1 row
     * If mapperId > r => will not get extra 1 row
     */
    if tableName == "S" then
        let r = sNumRows % sNumMappers in
            let q = sNumRows / sNumMappers in
                if r == 0 then q else if mapperId <= r then q + 1 else q
    else
        let r = tNumRows % tNumMappers in
            let q = tNumRows / tNumMappers in
                if r == 0 then q else if mapperId <= r then q + 1 else q
)

trigger understandData: (collection {Row: int, Regions: mut collection {RegionId: int} @ {Collection}} @ {Collection}, collection {Column: int, Regions: mut collection {RegionId: int} @ {Collection}} @ {Collection}, collection {Address: address, Id: int} @ {Collection}, int, int) = \data -> (
    bind data as (_rowLookupTable, _columnLookupTable, _reducers, _sNumRows, _tNumRows, _thresholdDate) in (
        rowLookupTable = _rowLookupTable;
        columnLookupTable = _columnLookupTable;
        reducers = _reducers;
        sNumRows = _sNumRows;
        tNumRows = _tNumRows;
        thresholdDate = _thresholdDate
    )
)

trigger arrangeMap: () = \_ -> (
    /*
     * Copy data to other mappers. == Put all shared data in this subroutine network call; also update understandData ==
     * Sending lookup tables and a list of reducers to each mapper as output needs to be routed to all reducers irrespective of the data;
     * also the reducers are created on fly using a script; therefore sending a collection of reducer addresses seems ideal. 
     */

    sMappers.iterate (\mapper -> (
        (understandData, mapper.Address) <- (rowLookupTable, columnLookupTable, reducers, sNumRows, tNumRows, thresholdDate)
    ));

    tMappers.iterate (\mapper -> (
        (understandData, mapper.Address) <- (rowLookupTable, columnLookupTable, reducers, sNumRows, tNumRows, thresholdDate)
    ));

    /* Send rows to specific mappers */
    sTable.fold (\mapperCounter -> \row -> (
        (sendRowToMapper_s, me) <- (row, (mapperCounter % sNumMappers) + 1);
        mapperCounter + 1
    )) 0;

    tTable.fold (\mapperCounter -> \row -> (
        (sendRowToMapper_t, me) <- (row, (mapperCounter % sNumMappers) + 1);
        mapperCounter + 1
    )) 0
)

/*
 * Feedback:
 * 1. Not sure if this is the right approach to send the rows to different mappers one by one -> network congestion.
 * 2. Create rowOutputForMapper collection to collect mapper rows for each mapper.
 */

trigger sendRowToMapper_s: ({Id: int, PageURL: string, PageRank: int}, int) = \x -> (
    bind x as (sRow, mapperId) in (
        let mapperSize = (getMapperSize mapperId "S") in
            let fMappers = sMappers.filter (\mapper -> (mapper.Id == mapperId)) in
                let mapperInstance = fMappers.peek() in
                    case mapperInstance of 
                    {Some mapper -> (map_s, mapper.Address) <- (sRow, mapperSize)}
                    {None -> ()}
    )
)

trigger sendRowToMapper_t: ({Id: int, SourceIP: string, DestURL: string, VisitDate: {y: int, m: int, d: int}, AdRevenue: real}, int) = \x -> (
    bind x as (tRow, mapperId) in (
        let mapperSize = (getMapperSize mapperId "T") in
            let fMappers = tMappers.filter (\mapper -> (mapper.Id == mapperId)) in
                let mapperInstance = fMappers.peek() in
                    case mapperInstance of
                    {Some mapper -> (map_t, mapper.Address) <- (tRow, mapperSize)}
                    {None -> ()}
    )
)

/* Implement Mapper Functionality */

declare _sTmpMapperOutputCollection: mut collection {Id: int, PageURL: string, PageRank: int} @ {Collection}
declare _tTmpMapperOutputCollection: mut collection {Id: int, SourceIP: string, DestURL: string, VisitDate: {y: int, m: int, d: int}, AdRevenue: real} @ {Collection}

trigger map_s: ({Id: int, PageURL: string, PageRank: int}, int) = \x -> (
    bind x as (sRow, mapperSize) in (
        sCurrentMapperSize = sCurrentMapperSize + 1;
        /*
         * Find the specific row in the lookup table.
         * Lookup all the regions associated to that row.
         * Find the mapper output associated with that region using the RegionId field.
         * Create a new output if output is None; otherwise, insert the row in the existing output and update collection.
         */
        let optLookupRow = (rowLookupTable.filter (\lookupRow -> lookupRow.Row == _randomRow)).peek() in
            case optLookupRow of
            {Some lookupRow -> (
                lookupRow.Regions.iterate (\region -> (
                    let optOldOutput = (sMapperOutput.filter (\output -> output.RegionId == region.RegionId)).peek() in
                        case optOldOutput of
                        {Some oldOutput -> (
                            let newOutput = oldOutput.Output in
                                newOutput.insert {Id: sRow.Id, PageURL: sRow.PageURL, PageRank: sRow.PageRank};
                                sMapperOutput.update {RegionId: region.RegionId, Output: oldOutput.Output} {RegionId: region.RegionId, Output: newOutput}
                        )}
                        {None -> (
                            _sTmpMapperOutputCollection = _sTmpMapperOutputCollection.filter (\outputCollection -> outputCollection.Age == -1);
                            _sTmpMapperOutputCollection.insert {Id: sRow.Id, PageURL: sRow.PageURL, PageRank: sRow.PageRank};
                            sMapperOutput.insert {RegionId: region.RegionId, Output: _sTmpMapperOutputCollection}
                        )}
                ))
            )}
            {None -> ()};

        /* After computing on mapperSize amount of rows, we then send the data to the reudcers */
        if sCurrentMapperSize == mapperSize then (sendAllToReducer, me) <- ()
        else ()
    )
)

trigger map_t: ({Id: int, SourceIP: string, DestURL: string, VisitDate: {y: int, m: int, d: int}, AdRevenue: real}, int) = \x -> (
    bind x as (tRow, mapperSize) in (
        tCurrentMapperSize = tCurrentMapperSize + 1;
        /*
         * Find the specific column in the lookup table.
         * Lookuo all the regions associated to that column.
         * Find the mapper output associated with that region using the RegionId field.
         * Create a new output if output is None; otherwise, insert the column(row) in the existing output and update collection.
         */
        let optLookupColumn = (columnLookupTable.filter (\lookupColumn -> lookupColumn.Column == _randomColumn)).peek() in
            case optLookupColumn of
            {Some lookupColumn -> (
                lookupColumn.Regions.iterate (\region -> (
                    let optOldOutput = (tMapperOutput.filter (\output -> output.RegionId == region.RegionId)).peek() in
                        case optOldOutput of
                        {Some oldOutput -> (
                            let newOutput = oldOutput.Output in
                                newOutput.insert {Id: tRow.Id, SourceIP: tRow.SourceIP, DestURL: tRow.DestURL, VisitDate: tRow.VisitDate, AdRevenue: tRow.AdRevenue};
                                tMapperOutput.update {RegionId: region.RegionId, Output: oldOutput.Output} {RegionId: region.RegionId, Output: newOutput}
                        )}
                        {None -> (
                            _tTmpMapperOutputCollection = _tTmpMapperOutputCollection.filter (\outputCollection -> outputCollection.Age == -1);
                            _tTmpMapperOutputCollection.insert {Id: tRow.Id, SourceIP: tRow.SourceIP, DestURL: tRow.DestURL, VisitDate: tRow.VisitDate, AdRevenue: tRow.AdRevenue};
                            tMapperOutput.insert {RegionId: region.RegionId, Output: _tTmpMapperOutputCollection}
                        )}
                ))
            )}
            {None -> ()};

        /* After computing on mapperSize amount of rows, we then send the data to the reudcers */
        if tCurrentMapperSize == mapperSize then (sendAllToReducer, me) <- ()
        else ()
    )
)

/* PHASE 3: REDUCER */

declare createDate: string -> {y: int, m: int, d: int} = fun dateString -> (
    let date = parseDate "%Y-%m-%d" dateString in
        case date of
        {Some n -> n}
        {None -> ()}
)

declare isDateLessThan: immut ({y: int, m: int, d: int} -> {y: int, m: int, d: int} -> bool) = fun date1 -> fun date2 -> (
    if date1.y != date2.y then
        date1.y < date2.y
    else if date1.m != date2.m then
        date1.m < date2.m
    else date1.d < date2.d
)

declare _sEmptyCollection: collection {Id: int, PageURL: string, PageRank: int} @ {Collection}
declare _tEmptyCollection: collection {Id: int, SourceIP: string, DestURL: string, VisitDate: {y: int, m: int, d: int}, AdRevenue: real} @ {Collection}

trigger sendAllToReducer: () = \_ -> (
    /*
     * 1. This method is called by every mapper once: (sendAllToReducer, me) <- (). Therefore every mapper sends something to all reducers.
     * 2. For every reducer, check if the mapper has some output for it. If so, send the output; else send () data.
     */
    reducers.iterate (\reducer -> (
        let mapperOutputCorrespondingToReducer = (sMapperOutput.filter (\mapperOutput -> mapperOutput.RegionId == reducer.Id)).peek() in
            case mapperOutputCorrespondingToReducer of
            {Some mapperOutput -> (reduce_s, reducer.Address) <- mapperOutput.Output}
            {None -> (reduce_s, reducer.Address) <- _sEmptyCollection};

        let mapperOutputCorrespondingToReducer = (tMapperOutput.filter (\mapperOutput -> mapperOutput.RegionId == reducer.Id)).peek() in
            case mapperOutputCorrespondingToReducer of
            {Some mapperOutput -> (reduce_t, reducer.Address) <- mapperOutput.Output}
            {None -> (reduce_t, reducer.Address) <- _tEmptyCollection}
    ))
)

declare _sMapperReceiveCounter: mut int = 0
declare _tMapperReceiveCounter: mut int = 0

trigger reduce_s: (collection {Id: int, PageURL: string, PageRank: int} @ {Collection}) = \coll -> (
    _sMapperReceiveCounter = _sMapperReceiveCounter + 1;
    coll.iterate (\row -> (
        sTuples.insert {Id: row.Id, PageURL: row.PageURL, PageRank: row.PageRank}
    ));
    let totalMappers = sNumMappers + tNumMappers in
        if (_sMapperReceiveCounter == totalMappers and _tMapperReceiveCounter == totalMappers) then
            (reduceDoJoin, me) <- ()
        else ()
)

trigger reduce_t: (collection {Id: int, SourceIP: string, DestURL: string, VisitDate: {y: int, m: int, d: int}, AdRevenue: real} @ {Collection}) = \coll -> (
    _tMapperReceiveCounter = _tMapperReceiveCounter + 1;
    coll.iterate (\row -> (
        tTuples.insert {Id: row.Id, SourceIP: row.SourceIP, DestURL: row.DestURL, VisitDate: row.VisitDate, AdRevenue: row.AdRevenue}
    ));
    let totalMappers = sNumMappers + tNumMappers in
        if (_sMapperReceiveCounter == totalMappers and _tMapperReceiveCounter == totalMappers) then
            (reduceDoJoin, me) <- ()
        else ()
)

declare reducerOutput: collection {SId: int, TId: int, SourceIP: string, PageRank: int, AdRevenue: real} @ {Collection}

trigger reduceDoJoin: () = \_ -> (
    sTuples.iterate (\sRow -> (
        tTuples.iterate (\tRow -> (
            let lDate = {y: 1980, m: 1, d: 1} in
            if sRow.PageURL == tRow.DestURL and (tRow.VisitDate > (createDate "1980-01-01") and tRow.VisitDate < thresholdDate) then
                reducerOutput.insert {SId: sRow.Id, TId: tRow.Id, SourceIP: tRow.SourceIP, PageRank: sRow.PageRank, AdRevenue: tRow.AdRevenue}
            else ()
        ))
    ));

    (accumulateOutput, master) <- (reducerOutput)
)

/* PHASE 4: ACCUMULATE OUTPUT */

declare reducerReceiveCounter: mut int = 0
declare groupBySourceIPCollection: collection {SId: int, TId: int, SourceIP: string, PageRank: int, AdRevenue: real} @ {Collection}

trigger accumulateOutput: (collection {SId: int, TId: int, SourceIP: string, PageRank: int, AdRevenue: real} @ {Collection}) = \reducerOutput -> (
    reducerReceiveCounter = reducerReceiveCounter + 1;
    reducerOutput.iterate (\outputRecord -> (
        groupBySourceIPCollection.insert {SId: reducerOutput.SId, TId: reducerOutput.TId, SourceIP: reducerOutput.SourceIP, PageRank: reducerOutput.PageRank, AdRevenue: reducerOutput.AdRevenue}
    ))
)

source tableSource: ({fromS: bool, sRow: option {PageURL: string, PageRank: int, AvgDuration: int}, tRow: option {SourceIP: string, DestURL: string, VisitDate: {y: int, m: int, d: int}, AdRevenue: real, UserAgent: string, CountryCode: string, LanguageCode: string, SearchWord: string, Duration: int}}) = file "/Users/kartikthapar/WorkCenter/Projects/K3/core/examples/sqlBenchmarking/R_UV_Tables.text" k3

feed tableSource |> preProcessTableRows
