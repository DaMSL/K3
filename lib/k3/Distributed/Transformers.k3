include "Annotation/Collection.k3"
include "Annotation/Map.k3"
include "Core/Barrier.k3"
include "Core/Builtins.k3"
include "Core/Messaging.k3"

control DistributedCollectionStatistics [ lbl         : label
                                        , query_cl    : [{cl:label, ce:expr}]
                                        , coordinator : expr
                                        , nodes       : expr
                                        , next        : expr ]
{
  ?e => $[lbl]_get_cstats(); $.[e]
     +> {
          // Statistics data structure populated at the coordinator.
          // Key is bucket address, value is bucket size.
          declare $[lbl]_cstats : mut collection {key: address, value: $[|
            -- This metaprogram creates a K3 record type using the list of collection labels.
            -- Each field is an integer type, to store the number of keys in the distributed collection.
            -- {<clbl 1> : int, <clbl 2> : int}
            let recErr _ = error "Invalid collection statistics type record" in
            let sizeFieldLT cRec = spliceRecordField cRec "cl" >>= idOfSLabel >>= \clbl -> return (clbl,TC.int)
            in maybe (recErr ()) (SType . TC.record) (elemsOfSList 'query_cl >>= mapM sizeFieldLT)
          |]} @Map

          // Use this method to gather collection statistics at the coordinator.
          declare $[lbl]_get_cstats : () -> () = \_ -> (
            $[nodes].iterate (\p -> ($[lbl]_collect_cstats, p.addr) <- ())
          )

          // Worker-side trigger to respond to statistics queries.
          trigger $[lbl]_collect_cstats : () = \_ -> (
            ($[lbl]_node_cstats, $[coordinator]) <- (me, $[|
              -- This metaprogram creates a record expression that contains fields
              -- populated with all of the desired collection sizes.
              let recErr _ = error "Invalid collection statistics record expr" in
              let sizeFieldLE cRec = do { l <- (spliceRecordField cRec "cl" >>= idOfSLabel);
                                          e <- (spliceRecordField cRec "ce" >>= expOfSExpr);
                                          return (l, EC.applyMany (EC.project "size" e) [EC.unit]) }
              in maybe (recErr ()) (SExpr . EC.record) (elemsOfSList 'query_cl >>= mapM sizeFieldLE)
            |])
          )

          // Coordinator-side trigger to accumulate collection statistics returns.
          // It prints the bucket distribution when all nodes are done reporting.
          trigger $[lbl]_node_cstats : (address, $[|
            -- This is the same K3 record constructor metaprogram as above.
            -- We could provide a common context of splice values in control annotation rewrites
            -- or support proper arbitrary nesting of Haskell/K3 metaprograms with a K3 quasiquoter.
            let recErr _ = error "Invalid collection statistics type record" in
            let sizeFieldLT cRec = spliceRecordField cRec "cl" >>= idOfSLabel >>= \clbl -> return (clbl,TC.int)
            in maybe (recErr ()) (SType . TC.record) (elemsOfSList 'query_cl >>= mapM sizeFieldLT)
          |])
          = \ns -> (
            (bind ns as (bucket_addr, cbucket_sizes) in
              $[lbl]_cstats.insert {key: bucket_addr, value: cbucket_sizes});
            ( print ($[|exprLabel 'lbl|] ++ " buckets: " ++
                      ($[lbl]_cstats.fold (\acc -> \r -> (acc ++ atos(r.key) ++ " => " ++ $[|
                      -- This metaprogram flattens all collection sizes into a K3 string expression.
                      let strError _ = error "Invalid collection statistics report" in
                      let sizeStr flbl = EC.applyMany (EC.variable "itos")
                                           [EC.project flbl $ EC.project "value" $ EC.variable "r"] in
                      let reportStr acc cRec = do { clbl <- spliceRecordField cRec "cl" >>= idOfSLabel;
                                                    return $ EC.binop OConcat acc
                                                           $ EC.binop OConcat (sizeStr clbl)
                                                           $ EC.constant (CString " ") }
                      in
                      let repExpr cRecs = foldM reportStr (EC.constant (CString "")) cRecs in
                      maybe (strError ()) SExpr $ (elemsOfSList 'query_cl >>= repExpr)
                      |]
                      )) ""));
              $[next]
            ) @OnCounter(id=[# $[lbl]_cstats_done], eq=[$ $[nodes].size()], reset=[$ false], profile=[$ false])
          )
        }
}


// Distributed Group By Implementation
// Enabling profiling will display the total elapsed time for the operator
// And skew statistics, namely:
//   - Difference in time between first and last peer finished with the group-by
//   - Number of keys assigned to each peer

control DistributedGroupByGeneric [ lbl             : label
                                  , peer_next       : expr
                                  , next            : expr
                                  , merge           : expr
                                  , coordinator     : expr
                                  , nodes           : expr
                                  , profile         : expr ]
{
  ignore ( (?e.groupBy ?groupF ?aggF ?accE) : collection ?t )
     => ((if $[profile]
          then $[lbl]_start_ts = now_int ()
          else ());
        $[nodes].iterate (\p -> ($[lbl]_scan, p.addr) <- ()) )
     +> {
          declare $[lbl]_start_ts : mut int = 0
          declare $[lbl]_end_ts : mut int = 0

          trigger $[lbl]_scan : () = \_ -> (
            (ignore ( $.[e].groupBy $.[groupF] $.[aggF] $.[accE]
            ) @SendPartitionByKey( dest_trg    = [$ $[lbl]_merge]
                                 , barrier_trg = [$ $[lbl]_peer_barrier]
                                 , nodes       = nodes ))
          )

          // Note: SendByPartitionKey always uses a @Collection for the wire type.
          trigger $[lbl]_merge : collection $::[t] @Collection = \partials -> (
            partials.iterate (\w -> $[merge] w)
          )

          trigger $[lbl]_peer_barrier : () = \_ -> (
            ( $[peer_next] ;
              ( $[lbl]_global_barrier, $[coordinator] ) <- ()
            ) @OnCounter(id=[# $[lbl]_peer_done], eq=[$ $[nodes].size()], reset=[$ false], profile=[$ false])
          )

          trigger $[lbl]_global_barrier : () = \_ -> (
            ( if $[profile]
                then ( $[lbl]_end_ts = now_int ();
                       let elapsed = $[lbl]_end_ts - $[lbl]_start_ts
                       in print ($[|exprLabel 'lbl|] ++ " total time: " ++ (itos elapsed))
                     )
                else ();
              $[next]
            ) @OnCounter(id=[# $[lbl]_done], eq=[$ $[nodes].size()], reset=[$ false], profile=[$ $[profile]])
          )
        }
}

control DistributedGroupBy [ lbl             : label
                           , peer_next       : expr
                           , next            : expr
                           , merge           : expr
                           , coordinator     : expr
                           , nodes           : expr
                           , profile         : expr ]
{
  ignore ( (?e.groupBy ?groupF ?aggF ?accE) : collection ?t )
     => (ignore ($.[e].groupBy $.[groupF] $.[aggF] $.[accE]))
          @DistributedGroupByGeneric(
              lbl         = lbl
            , peer_next   = [$ $[peer_next] $[lbl]_result ]
            , next        = next
            , merge       = [$ (\v ->
                                  $[lbl]_result.insert_with v (\a -> \b ->
                                    {key:a.key, value: $[merge] a.value b.value}))
                            ]
            , coordinator = coordinator
            , nodes       = nodes
            , profile     = [$ $[profile] ] )

     +> { declare $[lbl]_result : mut collection $::[t] @Map }
}


control DistributedHashJoin [ lbl             : label
                            , lhs_query       : expr
                            , rhs_query       : expr
                            , lhs_build_merge : expr
                            , rhs_probe_merge : expr
                            , peer_next       : expr
                            , next            : expr
                            , coordinator     : expr
                            , nodes           : expr
                            , lhs_build_ty    : type
                            , rhs_probe_ty    : type
                            ]
{
  () => $[nodes].iterate (\p -> ($[lbl]_lhs_scan, p.addr) <- ())
     +> {
        trigger $[lbl]_lhs_scan : () = \_ -> (
          (ignore
            ( $[lhs_query]
            ) @SendPartitionByKey( dest_trg    = [$ $[lbl]_build_lhs]
                                 , barrier_trg = [$ $[lbl]_lhs_peer_barrier]
                                 , nodes       = nodes))
        )

        trigger $[lbl]_build_lhs : $[lhs_build_ty] = \vals -> (
          vals.iterate $[lhs_build_merge]
        )

        trigger $[lbl]_lhs_peer_barrier : () = \_ -> (
          print "Hash join LHS finished build." ;
          ( $[nodes].iterate (\p -> ($[lbl]_rhs_scan, p.addr) <- ())
          ) @OnCounter(id=[# $[lbl]_peer_build_done], eq=[$ $[nodes].size()], reset=[$ false], profile=[$ false])
        )

        trigger $[lbl]_rhs_scan : () = \_ -> (
          (( ignore
              ( $[rhs_query]
              ) @SendPartitionByKey( dest_trg    = [$ $[lbl]_probe_rhs]
                                   , barrier_trg = [$ $[lbl]_rhs_peer_barrier]
                                   , nodes       = nodes))
          ) @OnCounter(id=[# $[lbl]_lhs_done], eq=[$ $[nodes].size()], reset=[$ false], profile=[$ false])
        )

        trigger $[lbl]_probe_rhs : $[rhs_probe_ty] = \vals -> (
          // Probe LHS hash table.
          vals.iterate $[rhs_probe_merge]
        )

        trigger $[lbl]_rhs_peer_barrier : () = \_ -> (
          ( print "Hash join RHS finished probe." ;
            $[peer_next] ;
            ($[lbl]_global_barrier, $[coordinator]) <- ()
          ) @OnCounter(id=[# $[lbl]_rhs_done], eq=[$ $[nodes].size()], reset=[$ false], profile=[$ false])
        )

        trigger $[lbl]_global_barrier : () = \_ -> (
          ( print "Hash join done." ;
            $[next]
          ) @OnCounter(id=[# $[lbl]_join_done], eq=[$ $[nodes].size()], reset=[$ false], profile=[$ false])
        )
     }
}
