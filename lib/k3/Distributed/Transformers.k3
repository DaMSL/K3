include "Annotation/Collection.k3"
include "Annotation/Map.k3"
include "Core/Barrier.k3"
include "Core/Builtins.k3"
include "Core/MachineMessaging.k3"

control DistributedCollectionStatistics [ lbl         : label
                                        , query_cl    : [{cl:label, ce:expr}]
                                        , coordinator : expr
                                        , nodes       : expr
                                        , next        : expr ]
{
  ?e => $[lbl]_get_cstats(); $.[e]
     +> {
          // Statistics data structure populated at the coordinator.
          // Key is bucket address, value is bucket size.
          declare $[lbl]_cstats : mut collection {key: address, value: $[|
            -- This metaprogram creates a K3 record type using the list of collection labels.
            -- Each field is an integer type, to store the number of keys in the distributed collection.
            -- {<clbl 1> : int, <clbl 2> : int}
            let recErr _ = error "Invalid collection statistics type record" in
            let sizeFieldLT cRec = spliceRecordField cRec "cl" >>= idOfSLabel >>= \clbl -> return (clbl,TC.int)
            in maybe (recErr ()) (SType . TC.record) (elemsOfSList 'query_cl >>= mapM sizeFieldLT)
          |]} @Map

          // Use this method to gather collection statistics at the coordinator.
          declare $[lbl]_get_cstats : () -> () = \_ -> (
            $[nodes].iterate (\p -> ($[lbl]_collect_cstats, p.addr) <- ())
          )

          // Worker-side trigger to respond to statistics queries.
          trigger $[lbl]_collect_cstats : () = \_ -> (
            ($[lbl]_node_cstats, $[coordinator]) <- (me, $[|
              -- This metaprogram creates a record expression that contains fields
              -- populated with all of the desired collection sizes.
              let recErr _ = error "Invalid collection statistics record expr" in
              let sizeFieldLE cRec = do { l <- (spliceRecordField cRec "cl" >>= idOfSLabel);
                                          e <- (spliceRecordField cRec "ce" >>= expOfSExpr);
                                          return (l, EC.applyMany (EC.project "size" e) [EC.unit]) }
              in maybe (recErr ()) (SExpr . EC.record) (elemsOfSList 'query_cl >>= mapM sizeFieldLE)
            |])
          )

          // Coordinator-side trigger to accumulate collection statistics returns.
          // It prints the bucket distribution when all nodes are done reporting.
          trigger $[lbl]_node_cstats : (address, $[|
            -- This is the same K3 record constructor metaprogram as above.
            -- We could provide a common context of splice values in control annotation rewrites
            -- or support proper arbitrary nesting of Haskell/K3 metaprograms with a K3 quasiquoter.
            let recErr _ = error "Invalid collection statistics type record" in
            let sizeFieldLT cRec = spliceRecordField cRec "cl" >>= idOfSLabel >>= \clbl -> return (clbl,TC.int)
            in maybe (recErr ()) (SType . TC.record) (elemsOfSList 'query_cl >>= mapM sizeFieldLT)
          |])
          = \ns -> (
            (bind ns as (bucket_addr, cbucket_sizes) in
              $[lbl]_cstats.insert {key: bucket_addr, value: cbucket_sizes});
            ( print ($[|exprLabel 'lbl|] ++ " buckets: " ++
                      ($[lbl]_cstats.fold (\acc -> \r -> (acc ++ atos(r.key) ++ " => " ++ $[|
                      -- This metaprogram flattens all collection sizes into a K3 string expression.
                      let strError _ = error "Invalid collection statistics report" in
                      let sizeStr flbl = EC.applyMany (EC.variable "itos")
                                           [EC.project flbl $ EC.project "value" $ EC.variable "r"] in
                      let reportStr acc cRec = do { clbl <- spliceRecordField cRec "cl" >>= idOfSLabel;
                                                    return $ EC.binop OConcat acc
                                                           $ EC.binop OConcat (sizeStr clbl)
                                                           $ EC.constant (CString " ") }
                      in
                      let repExpr cRecs = foldM reportStr (EC.constant (CString "")) cRecs in
                      maybe (strError ()) SExpr $ (elemsOfSList 'query_cl >>= repExpr)
                      |] ++ "\\n"
                      )) ""));
              $[next]
            ) @OnCounter(id=[# $[lbl]_cstats_done], eq=[$ $[nodes].size()], reset=[$ false], profile=[$ false])
          )
        }
}

// Distributed Group By Implementation
// Enabling profiling will display the total elapsed time for the operator

control DistributedGroupByGeneric [ lbl             : label
                                  , clear_expr      : expr
                                  , peer_next       : expr
                                  , next            : expr
                                  , merge           : expr
                                  , coordinator     : expr
                                  , nodes           : expr
                                  , masters         : expr
                                  , masters_map     : expr
                                  , profile         : expr ]
{
  ignore ( (?e.groupBy ?groupF ?aggF ?accE) : collection ?t )
     => (if $[profile]
          then (() @:StartTimer) @Time(lbl=[# $[lbl]_GROUPBY], tag=[$ "Time "])
          else ()
        );
        $[nodes].iterate (\p -> ($[lbl]_redistribute, p.addr) <- ())
     +> {
          trigger $[lbl]_redistribute : () = \_ -> (
           ( (ignore ( ($.[e].groupBy $.[groupF] $.[aggF] $.[accE])
                            .fold  ((\acc -> \v -> ((acc.insert v); acc)) @:Accumulate)
                                   (empty $::[t] @Map)
            )) @PartitionShuffleWithMissing(
                  lbl           = lbl
                , dest_trg      = [$ $[lbl]_merge ]
                , nodes         = nodes
                , send_extra_fn = [$ \x -> x]
                , send_ty       = [: collection $::[t] @ Map ]
                )
          );
          // Done with the input collection, free to clear.
          $[clear_expr]
          )

          trigger $[lbl]_merge : collection $::[t] @Map = (\partials ->
          ((partials.iterate (\w -> $[merge] w));
            ( $[peer_next] ;
              ( $[lbl]_global_barrier, $[coordinator] ) <- ()
            ) @OnCounter(id=[# $[lbl]_peer_done], eq=[$ $[nodes].size()], reset=[$ false], profile=[$ false])
          ))

          trigger $[lbl]_global_barrier : () = \_ -> (
            ((if $[profile]
              then (() @:StopTimer) @Time(lbl=[# $[lbl]_GROUPBY ], tag=[$ "Time "])
              else ()
            );
            $[next]
            ) @OnCounter(id=[# $[lbl]_done], eq=[$ $[nodes].size()], reset=[$ false], profile=[$ false])
          )
        }
}

control DistributedGroupBy [ lbl             : label
                           , clear_expr      : expr
                           , peer_next       : expr
                           , next            : expr
                           , merge           : expr
                           , coordinator     : expr
                           , nodes           : expr
                           , masters         : expr
                           , masters_map     : expr
                           , profile         : expr ]
{
  ignore ( (?e.groupBy ?groupF ?aggF ?accE) : collection ?t )
     => (ignore ($.[e].groupBy $.[groupF] $.[aggF] $.[accE]))
          @DistributedGroupByGeneric(
              lbl         = lbl
            , clear_expr  = clear_expr
            , peer_next   = [$ $[peer_next] $[lbl]_result ]
            , next        = next
            , merge       = [$ (\v ->
                                  $[lbl]_result.insert_with v (\a -> \b ->
                                    {key:a.key, value: $[merge] a.value b.value}))
                            ]
            , coordinator = coordinator
            , nodes       = nodes
            , masters     = masters
            , masters_map = masters_map
            , profile     = [$ $[profile] ] )

     +> { declare $[lbl]_result : mut collection $::[t] @Map }
}

control DistributedHashJoin [ lbl              : label
                            , lhs_ht_id        : label
                            , lhs_query        : expr
                            , rhs_query        : expr
                            , lhs_ht_ty        : type
                            , rhs_ht_ty        : type
                            , lhs_insert_with  : expr
                            , lhs_probe        : expr
                            , has_outputs      : expr
                            , empty_out_buffer : expr
                            , pipeline_next    : expr
                            , lhs_clear_expr   : expr
                            , peer_next        : expr
                            , next             : expr
                            , coordinator      : expr
                            , nodes            : expr
                            , masters          : expr
                            , masters_map      : expr
                            , profile          : expr
                            ]
{
  () => (if $[profile]
          then (() @:StartTimer) @Time(lbl=[# $[lbl]_HASHJOIN ], tag=[$ "Time "])
          else ()
        );
        $[nodes].iterate (\p -> ($[lbl]_lhs_redistribute, p.addr) <- ())
     +> {
        declare $[lhs_ht_id] : mut collection $[lhs_ht_ty] @Map

        trigger $[lbl]_lhs_redistribute : () = \_ -> (
          (ignore $[lhs_query])
            @PartitionShuffleWithMissing(
              lbl           = [# $[lbl]_lhs]
            , dest_trg = [$ $[lbl]_lhs_process_redistribute]
            , nodes = nodes
            , send_extra_fn = [$ \x -> x]
            , send_ty = [: collection $[lhs_ht_ty] @ Map]
            )
        )

        trigger $[lbl]_lhs_process_redistribute : collection $[lhs_ht_ty] @Map = (\vals ->
        ((vals.iterate (\v -> $[lhs_ht_id].insert_with v $[lhs_insert_with]));
          ( $[nodes].iterate (\p -> ($[lbl]_rhs_redistribute, p.addr) <- ())
          ) @OnCounter(id=[# $[lbl]_peer_build_done], eq=[$ $[nodes].size()], reset=[$ false], profile=[$ false]))
        )

        trigger $[lbl]_rhs_redistribute : () = \_ -> (
          ((( ignore $[rhs_query])
                @PartitionShuffleWithMissing(
                  lbl           = [# $[lbl]_rhs]
                , dest_trg = [$ $[lbl]_rhs_process_redistribute]
                , nodes = nodes
                , send_extra_fn = [$ \x -> x]
                , send_ty = [: collection $[rhs_ht_ty] @ Map]
                )
          ) @OnCounter(id=[# $[lbl]_lhs_done], eq=[$ $[nodes].size()], reset=[$ false], profile=[$ false])
        ))

        trigger $[lbl]_rhs_process_redistribute : collection $[rhs_ht_ty] @Map = (\vals -> (
          // Probe LHS hash table.
          let outputs = vals.fold ($[lhs_probe] $[lhs_ht_id]) $[empty_out_buffer] in
          (if $[has_outputs] outputs then ( $[pipeline_next] outputs ) else ());
          ( ( $[lhs_clear_expr] $[lhs_ht_id] );
            ( $[peer_next] );
            ( $[lbl]_global_barrier, $[coordinator] ) <- ()
          ) @OnCounter(id=[# $[lbl]_rhs_done], eq=[$ $[nodes].size()], reset=[$ false], profile=[$ false])
          ))

        trigger $[lbl]_global_barrier : () = \_ -> (
          ( (if $[profile]
               then (() @:StopTimer) @Time(lbl=[# $[lbl]_HASHJOIN ], tag=[$ "Time "])
               else ()
            );
            $[next]
          ) @OnCounter(id=[# $[lbl]_join_done], eq=[$ $[nodes].size()], reset=[$ false], profile=[$ false])
        )
     }
}

control PipelinedBroadcastJoin [ lbl                 : label
                               , lhs_query           : expr
                               , rhs_query           : expr
                               , lhs_probe           : expr
                               , broadcast_ty        : type
                               , has_outputs         : expr
                               , empty_out_buffer    : expr
                               , pipeline_next       : expr
                               , peer_next           : expr
                               , next                : expr
                               , coordinator         : expr
                               , nodes               : expr
                               , masters             : expr
                               , masters_map         : expr ]
{
  () => $[nodes].iterate (\p -> ($[lbl]_broadcast, p.addr) <- ())
     +> {
          // Compute any LHS data structures needed for join, then start broadcast.
          trigger $[lbl]_broadcast : () = \_ -> (
            $[lhs_query];
            (( ignore $[rhs_query]
            ) @:Send
            ) @BroadcastByMachine( lbl           = [# $[lbl]_rj_bcast ]
                                 , dest_trg      = [$ $[lbl]_probe ]
                                 , masters       = masters
                                 , masters_map   = masters_map
                                 , send_ty       = broadcast_ty
                                 , send_extra_fn = [$ \x -> x ] )
          )

          // Process broadcasted partition from a peer, and pipeline its outputs.
          trigger $[lbl]_probe : $[broadcast_ty] = ((\vals -> (
            ( let outputs = vals.fold $[lhs_probe] $[empty_out_buffer] in
              if $[has_outputs] outputs then ( $[pipeline_next] outputs ) else () );
            (
              ( print "Broadcast join peer finished processing." );
              $[peer_next];
              ($[lbl]_global_barrier, $[coordinator]) <- ()
            ) @OnCounter(id=[# $[lbl]_peer_broadcast_done], eq=[$ $[nodes].size()], reset=[$ false], profile=[$ false])
          )
          ) @:Receive
          ) @BroadcastByMachine( lbl           = [# $[lbl]_rj_bcast ]
                               , dest_trg      = [$ $[lbl]_probe ]
                               , masters       = masters
                               , masters_map   = masters_map
                               , send_ty       = broadcast_ty
                               , send_extra_fn = [$ \x -> x ] )

          trigger $[lbl]_global_barrier : () = \_ -> (
            ( print "Broadcast join done." ;
              $[next]
            ) @OnCounter(id=[# $[lbl]_join_done], eq=[$ $[nodes].size()], reset=[$ false], profile=[$ false])
          )
        }
}

// This annotation generates the symmetric streaming phase
// of a pipelined symmetric hash join.
control StreamingHashJoin [ lbl                  : label
                          , lhs_ht_id            : label
                          , rhs_ht_id            : label
                          , lhs_ht_ty            : type
                          , rhs_ht_ty            : type
                          , lhs_probe            : expr
                          , rhs_probe            : expr
                          , lhs_insert_with      : expr
                          , rhs_insert_with      : expr
                          , has_outputs          : expr
                          , empty_out_buffer     : expr
                          , lhs_pipeline_next    : expr
                          , rhs_pipeline_next    : expr
                          , lhs_clear_expr       : expr
                          , rhs_clear_expr       : expr
                          , peer_next            : expr
                          , next                 : expr
                          , coordinator          : expr
                          , nodes                : expr
                          ]
{
  () => ()
     +> {
          declare $[lhs_ht_id] : mut collection $[lhs_ht_ty] @Map
          declare $[rhs_ht_id] : mut collection $[rhs_ht_ty] @Map

          declare $[lbl]_lhs_done : mut bool = false
          declare $[lbl]_rhs_done : mut bool = false

          trigger $[lbl]_process_redistribute : ( option (collection $[lhs_ht_ty] @Map)
                                                , option (collection $[rhs_ht_ty] @Map)
                                                , bool)
          = \rd -> (
            bind rd as (lv_opt, rv_opt, is_left) in (
              // Three stages: join other, pipeline outputs, track for other
              if is_left then (
                case lv_opt of
                { Some lvals ->
                  let outputs = lvals.fold ($[rhs_probe] $[rhs_ht_id]) $[empty_out_buffer] in
                  ((if $[has_outputs] outputs then ( $[lhs_pipeline_next] outputs ) else ());
                    if $[lbl]_rhs_done then () else ( lvals.iterate (\lkv -> $[lhs_ht_id].insert_with lkv $[lhs_insert_with]) ))
                }
                { None -> error (print ($[|exprLabel 'lbl|] ++ "_process_redistribute: invalid left join inputs.")) }
              ) else (
                case rv_opt of
                { Some rvals ->
                  let outputs = rvals.fold ($[lhs_probe] $[lhs_ht_id]) $[empty_out_buffer] in
                  ((if $[has_outputs] outputs then ( $[rhs_pipeline_next] outputs ) else ());
                    if $[lbl]_lhs_done then () else ( rvals.iterate (\rkv -> $[rhs_ht_id].insert_with rkv $[rhs_insert_with]) ))
                }
                { None -> error (print ($[|exprLabel 'lbl|] ++ "_process_redistribute: invalid right join inputs.")) }
              )
            )
          )

          trigger $[lbl]_lhs_peer_barrier : () = \_ -> (
            (
              // LHS is finished, we no longer need to build/probe the RHS
              ( $[lbl]_lhs_done = true );
              ( $[rhs_clear_expr] $[rhs_ht_id] );
              if not $[lbl]_rhs_done then () else (
                $[peer_next];
                ($[lbl]_global_barrier, $[coordinator]) <- ()
              )
            ) @OnCounter(id=[# $[lbl]_peer_lbuild_done], eq=[$ $[nodes].size()], reset=[$ false], profile=[$ false])
          )

          trigger $[lbl]_rhs_peer_barrier : () = \_ -> (
            (
              // RHS is finished, we no longer need to build/probe the LHS
              ( $[lbl]_rhs_done = true );
              ( $[lhs_clear_expr] $[lhs_ht_id] );
              if not $[lbl]_lhs_done then () else (
                $[peer_next];
                ($[lbl]_global_barrier, $[coordinator]) <- ()
              )
            ) @OnCounter(id=[# $[lbl]_peer_rbuild_done], eq=[$ $[nodes].size()], reset=[$ false], profile=[$ false])
          )

          trigger $[lbl]_global_barrier : () = \_ -> (
            ( print "Join done." ;
              $[next]
            ) @OnCounter(id=[# $[lbl]_join_done], eq=[$ $[nodes].size()], reset=[$ false], profile=[$ false])
          )
        }
}

control BarrierHashJoin   [ lbl                  : label
                          , lhs_ht_id            : label
                          , rhs_ht_id            : label
                          , lhs_ht_ty            : type
                          , rhs_ht_ty            : type
                          , lhs_probe            : expr
                          , rhs_probe            : expr
                          , lhs_insert_with      : expr
                          , rhs_insert_with      : expr
                          , has_outputs          : expr
                          , empty_out_buffer     : expr
                          , lhs_pipeline_next    : expr
                          , rhs_pipeline_next    : expr
                          , lhs_clear_expr       : expr
                          , rhs_clear_expr       : expr
                          , peer_next            : expr
                          , next                 : expr
                          , coordinator          : expr
                          , nodes                : expr
                          ]
{
  () => ()
     +> {
          declare $[lhs_ht_id] : mut collection $[lhs_ht_ty] @Map
          declare $[rhs_ht_id] : mut collection $[rhs_ht_ty] @Map

          trigger $[lbl]_process_redistribute : ( option (collection $[lhs_ht_ty] @Map)
                                                , option (collection $[rhs_ht_ty] @Map)
                                                , bool)
          = \rd -> (
            (bind rd as (lv_opt, rv_opt, is_left) in (
              // Three stages: join other, pipeline outputs, track for other
              if is_left then (
                case lv_opt of
                { Some lvals ->
                  let outputs = lvals.fold ($[rhs_probe] $[rhs_ht_id]) $[empty_out_buffer] in
                  ((if $[has_outputs] outputs then ( $[lhs_pipeline_next] outputs ) else ());
                    if $[lbl]_rhs_done then () else ( lvals.iterate (\lkv -> $[lhs_ht_id].insert_with lkv $[lhs_insert_with]) ))
                }
                { None -> error (print ($[|exprLabel 'lbl|] ++ "_process_redistribute: invalid left join inputs.")) }
              ) else (
                case rv_opt of
                { Some rvals ->
                  let outputs = rvals.fold ($[lhs_probe] $[lhs_ht_id]) $[empty_out_buffer] in
                  ((if $[has_outputs] outputs then ( $[rhs_pipeline_next] outputs ) else ());
                    if $[lbl]_lhs_done then () else ( rvals.iterate (\rkv -> $[rhs_ht_id].insert_with rkv $[rhs_insert_with]) ))
                }
                { None -> error (print ($[|exprLabel 'lbl|] ++ "_process_redistribute: invalid right join inputs.")) }
              )
            ));
            (
              ( $[lhs_clear_expr] $[lhs_ht_id] );
              ( $[rhs_clear_expr] $[rhs_ht_id] );
                $[peer_next];
                ($[lbl]_global_barrier, $[coordinator]) <- ()
            ) @OnCounter(id=[# $[lbl]_peer_done], eq=[$ $[nodes].size() * 2], reset=[$ false], profile=[$ false])
          )

          trigger $[lbl]_global_barrier : () = \_ -> (
            ( print "Join done." ;
              $[next]
            ) @OnCounter(id=[# $[lbl]_join_done], eq=[$ $[nodes].size()], reset=[$ false], profile=[$ false])
          )
        }
}

control PipelineSymmetricHashJoin [ lbl                  : label
                                  , lhs_ht_id            : label
                                  , rhs_ht_id            : label
                                  , lhs_query            : expr
                                  , rhs_query            : expr
                                  , lhs_ht_ty            : type
                                  , rhs_ht_ty            : type
                                  , lhs_probe            : expr
                                  , rhs_probe            : expr
                                  , lhs_insert_with      : expr
                                  , rhs_insert_with      : expr
                                  , has_outputs          : expr
                                  , empty_out_buffer     : expr
                                  , lhs_pipeline_next    : expr
                                  , rhs_pipeline_next    : expr
                                  , lhs_clear_expr       : expr
                                  , rhs_clear_expr       : expr
                                  , peer_next            : expr
                                  , next                 : expr
                                  , coordinator          : expr
                                  , nodes                : expr
                                  ]
{
  () => ( (() @StreamingHashJoin( lbl                  = lbl
                                , lhs_ht_id            = lhs_ht_id
                                , rhs_ht_id            = rhs_ht_id
                                , lhs_ht_ty            = lhs_ht_ty
                                , rhs_ht_ty            = rhs_ht_ty
                                , lhs_probe            = lhs_probe
                                , rhs_probe            = rhs_probe
                                , lhs_insert_with      = lhs_insert_with
                                , rhs_insert_with      = rhs_insert_with
                                , has_outputs          = has_outputs
                                , empty_out_buffer     = empty_out_buffer
                                , lhs_pipeline_next    = lhs_pipeline_next
                                , rhs_pipeline_next    = rhs_pipeline_next
                                , lhs_clear_expr       = lhs_clear_expr
                                , rhs_clear_expr       = rhs_clear_expr
                                , peer_next            = peer_next
                                , next                 = next
                                , coordinator          = coordinator
                                , nodes                = nodes ));

          $[nodes].iterate (\p -> ($[lbl]_redistribute, p.addr) <- ()) )
     +> {
          trigger $[lbl]_redistribute : () = \_ -> (
            (ignore
              ( $[lhs_query]
              ) @PSendPartitionByKey( dest_trg      = [$ $[lbl]_process_redistribute]
                                    , barrier_trg   = [$ $[lbl]_lhs_peer_barrier]
                                    , nodes         = nodes
                                    , send_extra_fn = [$ (\x -> (Some x, None immut, true))]));
            (ignore
              ( $[rhs_query]
              ) @PSendPartitionByKey( dest_trg      = [$ $[lbl]_process_redistribute]
                                    , barrier_trg   = [$ $[lbl]_rhs_peer_barrier]
                                    , nodes         = nodes
                                    , send_extra_fn = [$ (\x -> (None immut, Some x, false))]))
          )
        }
}


control SkewShuffle [ lbl             : label
                    , lhs             : expr
                    , skewed_keys     : expr
                    , query           : expr
                    , query_result_ty : type
                    , dest_trg        : expr
                    , barrier_trg     : expr
                    , nodes           : expr
                    , send_extra_fn   : expr
                    ]
{
  () =>
      // Three-component join parts of: round-robin, hash-based and replicated map distribution.
      let part = empty $[query_result_ty] @Map in

      let acc_parts = \acc -> \r -> (
        bind acc as (rr_c, redist_c, repl_c) in
        case $[skewed_keys].lookup {key: r.key, value: false} of
        { Some skew_r ->
            ((if skew_r.value then ( if $[lhs] then rr_c.insert   r else repl_c.insert r )
                              else ( if $[lhs] then repl_c.insert r else rr_c.insert   r ));
             (rr_c, redist_c, repl_c)) }
        { None -> ((redist_c.insert r); (rr_c, redist_c, repl_c)) })
      in

      let skew_parts = $[query].fold acc_parts (part, part, part) in

      // TODO: combine three components per destination peer.
      (bind skew_parts as (rr, redist, repl) in
        ( ignore (rr)     @PSendRoundRobin     ( dest_trg      = dest_trg
                                               , barrier_trg   = barrier_trg
                                               , nodes         = nodes
                                               , send_extra_fn = send_extra_fn ) );

        ( ignore (redist) @PSendPartitionByKey ( dest_trg      = dest_trg
                                               , barrier_trg   = barrier_trg
                                               , nodes         = nodes
                                               , send_extra_fn = send_extra_fn ) );

        ( ignore (repl)   @PSendBroadcast      ( dest_trg      = dest_trg
                                               , barrier_trg   = barrier_trg
                                               , nodes         = nodes
                                               , send_extra_fn = send_extra_fn ) ))
}

control PipelineSkewJoin [ lbl                  : label
                         , lhs_ht_id            : label
                         , rhs_ht_id            : label
                         , lhs_sample_query     : expr
                         , rhs_sample_query     : expr
                         , frequency_threshold  : expr
                         , lhs_query            : expr
                         , rhs_query            : expr
                         , join_key_ty          : type
                         , lhs_ht_ty            : type
                         , rhs_ht_ty            : type
                         , lhs_probe            : expr
                         , rhs_probe            : expr
                         , lhs_insert_with      : expr
                         , rhs_insert_with      : expr
                         , has_outputs          : expr
                         , empty_out_buffer     : expr
                         , lhs_pipeline_next    : expr
                         , rhs_pipeline_next    : expr
                         , lhs_clear_expr       : expr
                         , rhs_clear_expr       : expr
                         , peer_next            : expr
                         , next                 : expr
                         , coordinator          : expr
                         , nodes                : expr
                         ]
{
    () => ( (() @StreamingHashJoin( lbl                  = lbl
                                  , lhs_ht_id            = lhs_ht_id
                                  , rhs_ht_id            = rhs_ht_id
                                  , lhs_ht_ty            = lhs_ht_ty
                                  , rhs_ht_ty            = rhs_ht_ty
                                  , lhs_probe            = lhs_probe
                                  , rhs_probe            = rhs_probe
                                  , lhs_insert_with      = lhs_insert_with
                                  , rhs_insert_with      = rhs_insert_with
                                  , has_outputs          = has_outputs
                                  , empty_out_buffer     = empty_out_buffer
                                  , lhs_pipeline_next    = lhs_pipeline_next
                                  , rhs_pipeline_next    = rhs_pipeline_next
                                  , lhs_clear_expr       = lhs_clear_expr
                                  , rhs_clear_expr       = rhs_clear_expr
                                  , peer_next            = peer_next
                                  , next                 = next
                                  , coordinator          = coordinator
                                  , nodes                = nodes ));
            $[nodes].iterate (\p -> ($[lbl]_sample, p.addr) <- ()) )
     +> {
          // Algorithm:
          // Phase 1: collect statistics per peer
          // a. sample each partition, communicate to coordinator
          // b. populate pair counts, and filter extreme values for either pair element based on threshold.
          // c. distribute list of extreme values and source to peers.
          //
          // Phase 2: peer post-query phase
          // each data structure below is a key -> (value collection) mapping support duplicates
          // for each tuple in each side:
          //   if tuple is skewed: add to replicate or round-robin data structure based on source
          //   otherwise add to redistribute data structure
          // send out replicated, round-robin, and redistributed data structures
          //
          // Phase 3: peer receive phase
          // standard pipelined symmetric hashtable build/probe for all (i.e., repl/rr/redistributed) inputs

          // Join key histogram, storing frequency in both LHS and RHS relations.
          declare $[lbl]_hist : collection {key : $[join_key_ty], value : (int, int)} @Map

          declare $[lbl]_hist_merge :    {key: $[join_key_ty], value: (int, int)}
                                      -> {key: $[join_key_ty], value: (int, int)}
                                      -> {key: $[join_key_ty], value: (int, int)}
          = \a -> (\b ->
              bind a.value as (alf, arf) in
              bind b.value as (blf, brf) in
              {key: a.key, value: (alf + blf, arf + brf)})

          declare $[lbl]_acc_hifreq :   (collection {key: $[join_key_ty], value: bool} @Map)
                                     -> {key: $[join_key_ty], value: (int, int)}
                                     -> (collection {key: $[join_key_ty], value: bool} @Map)
          = \acc -> (\r ->
              bind r.value as (lfreq, rfreq) in
              let lsource = lfreq > rfreq in
              let maxfreq = if lfreq > rfreq then lfreq else rfreq in
              if maxfreq > $[frequency_threshold] then ((acc.insert {key: r.key, value: lsource}; acc))
                                                  else acc)

          trigger $[lbl]_sample : () = \_ -> (
            (($[lbl]_process_sample, $[coordinator]) <- ($[lhs_sample_query], true));
            (($[lbl]_process_sample, $[coordinator]) <- ($[rhs_sample_query], false));
            (($[lbl]_peer_sample_barrier, $[coordinator]) <- ())
          )

          trigger $[lbl]_process_sample : ( collection {key: $[join_key_ty], value: int} @Map, bool )
          = \slr -> (
            bind slr as (sampled_keys, from_left) in (
              (sampled_keys.iterate (\i ->
                let nvalue = if from_left then {key: i.key, value: (i.value, 0)}
                                          else {key: i.key, value: (0, i.value)}
                in $[lbl]_hist.insert_with nvalue $[lbl]_hist_merge))
            )
          )

          trigger $[lbl]_peer_sample_barrier : () = \_ -> (
            (
              // Compute high-frequency values
              let skewed = $[lbl]_hist.fold $[lbl]_acc_hifreq (empty {key: $[join_key_ty], value: bool} @Map)
              in (
                // Broadcast skewed values back to nodes.
                $[nodes].iterate (\n -> ($[lbl]_redistribute, n.addr) <- skewed )
              )
            ) @OnCounter(id=[# $[lbl]_peer_sample_done], eq=[$ $[nodes].size()], reset=[$ false], profile=[$ false])
          )

          trigger $[lbl]_redistribute : collection {key: $[join_key_ty], value: bool} @Map =
          \skewed_keys -> (
            () @SkewShuffle( lbl             = lbl
                           , lhs             = [$ true]
                           , skewed_keys     = [$ skewed_keys]
                           , query           = lhs_query
                           , query_result_ty = lhs_ht_ty
                           , dest_trg        = [$ $[lbl]_process_redistribute ]
                           , barrier_trg     = [$ $[lbl]_lhs_peer_barrier ]
                           , nodes           = nodes
                           , send_extra_fn   = [$ (\x -> (Some x, None immut, true)) ]) ;

            () @SkewShuffle( lbl             = lbl
                           , lhs             = [$ false]
                           , skewed_keys     = [$ skewed_keys]
                           , query           = rhs_query
                           , query_result_ty = rhs_ht_ty
                           , dest_trg        = [$ $[lbl]_process_redistribute ]
                           , barrier_trg     = [$ $[lbl]_rhs_peer_barrier ]
                           , nodes           = nodes
                           , send_extra_fn   = [$ (\x -> (None immut, Some x, false)) ])
          )
        }
}


control JoinSelector [ lbl                  : label
                     , lhs_ht_id            : label
                     , rhs_ht_id            : label
                     , lhs_sample_query     : expr
                     , rhs_sample_query     : expr
                     , frequency_threshold  : expr
                     , lhs_query            : expr
                     , rhs_query            : expr
                     , join_key_ty          : type
                     , lhs_ht_ty            : type
                     , rhs_ht_ty            : type
                     , lhs_probe            : expr
                     , rhs_probe            : expr
                     , lhs_insert_with      : expr
                     , rhs_insert_with      : expr
                     , has_outputs          : expr
                     , empty_out_buffer     : expr
                     , lhs_pipeline_next    : expr
                     , rhs_pipeline_next    : expr
                     , lhs_clear_expr       : expr
                     , rhs_clear_expr       : expr
                     , peer_next            : expr
                     , next                 : expr
                     , coordinator          : expr
                     , nodes                : expr
                     , masters              : expr
                     , masters_map          : expr
                     , profile              : expr
                     ]
{
  ( ?e ) @:Skew   => $.[e] @PipelineSkewJoin( lbl                  = [# $[lbl]_skew ]
                                            , lhs_ht_id            = lhs_ht_id
                                            , rhs_ht_id            = rhs_ht_id
                                            , lhs_sample_query     = lhs_sample_query
                                            , rhs_sample_query     = rhs_sample_query
                                            , frequency_threshold  = frequency_threshold
                                            , lhs_query            = lhs_query
                                            , rhs_query            = rhs_query
                                            , join_key_ty          = join_key_ty
                                            , lhs_ht_ty            = lhs_ht_ty
                                            , rhs_ht_ty            = rhs_ht_ty
                                            , lhs_probe            = lhs_probe
                                            , rhs_probe            = rhs_probe
                                            , lhs_insert_with      = lhs_insert_with
                                            , rhs_insert_with      = rhs_insert_with
                                            , has_outputs          = has_outputs
                                            , empty_out_buffer     = empty_out_buffer
                                            , lhs_pipeline_next    = lhs_pipeline_next
                                            , rhs_pipeline_next    = rhs_pipeline_next
                                            , lhs_clear_expr       = lhs_clear_expr
                                            , rhs_clear_expr       = rhs_clear_expr
                                            , peer_next            = peer_next
                                            , next                 = next
                                            , coordinator          = coordinator
                                            , nodes                = nodes)

  ( ?e ) @:NoSkew => $.[e] @PipelineSymmetricHashJoin( lbl                  = [# $[lbl]_pshj ]
                                                     , lhs_ht_id            = lhs_ht_id
                                                     , rhs_ht_id            = rhs_ht_id
                                                     , lhs_query            = lhs_query
                                                     , rhs_query            = rhs_query
                                                     , lhs_ht_ty            = lhs_ht_ty
                                                     , rhs_ht_ty            = rhs_ht_ty
                                                     , lhs_probe            = lhs_probe
                                                     , rhs_probe            = rhs_probe
                                                     , lhs_insert_with      = lhs_insert_with
                                                     , rhs_insert_with      = rhs_insert_with
                                                     , has_outputs          = has_outputs
                                                     , empty_out_buffer     = empty_out_buffer
                                                     , lhs_pipeline_next    = lhs_pipeline_next
                                                     , rhs_pipeline_next    = rhs_pipeline_next
                                                     , lhs_clear_expr       = lhs_clear_expr
                                                     , rhs_clear_expr       = rhs_clear_expr
                                                     , peer_next            = peer_next
                                                     , next                 = next
                                                     , coordinator          = coordinator
                                                     , nodes                = nodes)

  ( ?e ) @:NoSkewMM => $.[e] @MMPSHJ( lbl                  = [# $[lbl]_mmpshj ]
                                    , lhs_ht_id            = lhs_ht_id
                                    , rhs_ht_id            = rhs_ht_id
                                    , lhs_query            = lhs_query
                                    , rhs_query            = rhs_query
                                    , lhs_ht_ty            = lhs_ht_ty
                                    , rhs_ht_ty            = rhs_ht_ty
                                    , lhs_probe            = lhs_probe
                                    , rhs_probe            = rhs_probe
                                    , lhs_insert_with      = lhs_insert_with
                                    , rhs_insert_with      = rhs_insert_with
                                    , has_outputs          = has_outputs
                                    , empty_out_buffer     = empty_out_buffer
                                    , lhs_pipeline_next    = lhs_pipeline_next
                                    , rhs_pipeline_next    = rhs_pipeline_next
                                    , lhs_clear_expr       = lhs_clear_expr
                                    , rhs_clear_expr       = rhs_clear_expr
                                    , peer_next            = peer_next
                                    , next                 = next
                                    , coordinator          = coordinator
                                    , nodes                = nodes
                                    , masters              = masters
                                    , masters_map          = masters_map)

  ( ?e ) @:NoPipeline => $.[e] @DistributedHashJoin(  lbl              = [# $[lbl]_hj ]
                                                    , lhs_ht_id        = lhs_ht_id
                                                    , lhs_query        = lhs_query
                                                    , rhs_query        = rhs_query
                                                    , lhs_ht_ty        = lhs_ht_ty
                                                    , rhs_ht_ty        = rhs_ht_ty
                                                    , lhs_insert_with  = lhs_insert_with
                                                    , lhs_probe        = lhs_probe
                                                    , has_outputs      = has_outputs
                                                    , empty_out_buffer = empty_out_buffer
                                                    , pipeline_next    = rhs_pipeline_next
                                                    , lhs_clear_expr   = lhs_clear_expr
                                                    , peer_next        = peer_next
                                                    , next             = next
                                                    , coordinator      = coordinator
                                                    , nodes            = nodes
                                                    , masters          = masters
                                                    , masters_map      = masters_map
                                                    , profile          = profile
                                                    )

}


// Machine-messaging join variants
control MMPSHJ [ lbl                  : label
               , lhs_ht_id            : label
               , rhs_ht_id            : label
               , lhs_query            : expr
               , rhs_query            : expr
               , lhs_ht_ty            : type
               , rhs_ht_ty            : type
               , lhs_probe            : expr
               , rhs_probe            : expr
               , lhs_insert_with      : expr
               , rhs_insert_with      : expr
               , has_outputs          : expr
               , empty_out_buffer     : expr
               , lhs_pipeline_next    : expr
               , rhs_pipeline_next    : expr
               , lhs_clear_expr       : expr
               , rhs_clear_expr       : expr
               , peer_next            : expr
               , next                 : expr
               , coordinator          : expr
               , nodes                : expr
               , masters              : expr
               , masters_map          : expr
               ]
{
  () => ( $[nodes].iterate (\p -> ($[lbl]_redistribute, p.addr) <- ()) )
     +> {
          declare $[lhs_ht_id] : mut collection $[lhs_ht_ty] @Map
          declare $[rhs_ht_id] : mut collection $[rhs_ht_ty] @Map

          declare $[lbl]_lhs_done : mut bool = false
          declare $[lbl]_rhs_done : mut bool = false

          trigger $[lbl]_redistribute : () = \_ -> (
            ((ignore $[lhs_query]
            ) @:Send
            ) @ShuffleByMachine( lbl           = [# $[lbl]_pshj_shuffle ]
                               , punclbl       = [# $[lbl]_pshjl_shpunc ]
                               , dest_trg      = [$ $[lbl]_process_redistribute]
                               , barrier_trg   = [$ $[lbl]_lhs_peer_barrier]
                               , nodes         = nodes
                               , masters       = masters
                               , masters_map   = masters_map
                               , send_ty       = [: ( option collection $[lhs_ht_ty] @Map
                                                    , option collection $[rhs_ht_ty] @Map
                                                    , bool ) ]
                               , send_extra_fn = [$ (\x -> (Some x, None immut, true))] );

            ((ignore $[rhs_query]
            ) @:SendNoDecl
            ) @ShuffleByMachine( lbl           = [# $[lbl]_pshj_shuffle ]
                               , punclbl       = [# $[lbl]_pshjr_shpunc ]
                               , dest_trg      = [$ $[lbl]_process_redistribute]
                               , barrier_trg   = [$ $[lbl]_rhs_peer_barrier]
                               , nodes         = nodes
                               , masters       = masters
                               , masters_map   = masters_map
                               , send_ty       = [: ( option collection $[lhs_ht_ty] @Map
                                                    , option collection $[rhs_ht_ty] @Map
                                                    , bool ) ]
                               , send_extra_fn = [$ (\x -> (None immut, Some x, false))] )
          )

          trigger $[lbl]_process_redistribute : ( option (collection $[lhs_ht_ty] @Map)
                                                , option (collection $[rhs_ht_ty] @Map)
                                                , bool )
          = ((\rd -> (
            bind rd as (lv_opt, rv_opt, is_left) in (
              // Three stages: join other, pipeline outputs, track for other
              if is_left then (
                case lv_opt of
                { Some lvals ->
                  let outputs = lvals.fold ($[rhs_probe] $[rhs_ht_id]) $[empty_out_buffer] in
                  ((if $[has_outputs] outputs then ( $[lhs_pipeline_next] outputs ) else ());
                    if $[lbl]_rhs_done then () else ( lvals.iterate (\lkv -> $[lhs_ht_id].insert_with lkv $[lhs_insert_with]) ))
                }
                { None -> error (print ($[|exprLabel 'lbl|] ++ "_process_redistribute: invalid left join inputs.")) }
              ) else (
                case rv_opt of
                { Some rvals ->
                  let outputs = rvals.fold ($[lhs_probe] $[lhs_ht_id]) $[empty_out_buffer] in
                  ((if $[has_outputs] outputs then ( $[rhs_pipeline_next] outputs ) else ());
                    if $[lbl]_lhs_done then () else ( rvals.iterate (\rkv -> $[rhs_ht_id].insert_with rkv $[rhs_insert_with]) ))
                }
                { None -> error (print ($[|exprLabel 'lbl|] ++ "_process_redistribute: invalid right join inputs.")) }
              )
            )
          )
          ) @:Receive
          ) @ShuffleByMachine( lbl           = [# $[lbl]_pshj_shuffle ]
                             , punclbl       = [# unused ]
                             , dest_trg      = [$ $[lbl]_process_redistribute ]
                             , barrier_trg   = [$ () ]
                             , nodes         = nodes
                             , masters       = masters
                             , masters_map   = masters_map
                             , send_ty       = [: ( option collection $[lhs_ht_ty] @Map
                                                  , option collection $[rhs_ht_ty] @Map
                                                  , bool ) ]
                             , send_extra_fn = [$ \x -> x ] )

          trigger $[lbl]_lhs_peer_barrier : () = ((\_ -> (
            (
              // LHS is finished, we no longer need to build/probe the RHS
              ( $[lbl]_lhs_done = true );
              ( $[rhs_clear_expr] $[rhs_ht_id] );
              if not $[lbl]_rhs_done then () else (
                $[peer_next];
                ($[lbl]_global_barrier, $[coordinator]) <- ()
              )
            ) @OnCounter(id=[# $[lbl]_peer_lbuild_done], eq=[$ $[nodes].size()], reset=[$ false], profile=[$ false])
          )
          ) @:BarrierReceive
          ) @ShuffleByMachine( lbl           = [# unused ]
                             , punclbl       = [# $[lbl]_pshjl_shpunc ]
                             , dest_trg      = [$ () ]
                             , barrier_trg   = [$ () ]
                             , nodes         = nodes
                             , masters       = masters
                             , masters_map   = masters_map
                             , send_ty       = [: () ]
                             , send_extra_fn = [$ \x -> x ] )

          trigger $[lbl]_rhs_peer_barrier : () = ((\_ -> (
            (
              // RHS is finished, we no longer need to build/probe the LHS
              ( $[lbl]_rhs_done = true );
              ( $[lhs_clear_expr] $[lhs_ht_id] );
              if not $[lbl]_lhs_done then () else (
                $[peer_next];
                ($[lbl]_global_barrier, $[coordinator]) <- ()
              )
            ) @OnCounter(id=[# $[lbl]_peer_rbuild_done], eq=[$ $[nodes].size()], reset=[$ false], profile=[$ false])
          )
          ) @:BarrierReceive
          ) @ShuffleByMachine( lbl           = [# unused ]
                             , punclbl       = [# $[lbl]_pshjr_shpunc ]
                             , dest_trg      = [$ () ]
                             , barrier_trg   = [$ () ]
                             , nodes         = nodes
                             , masters       = masters
                             , masters_map   = masters_map
                             , send_ty       = [: () ]
                             , send_extra_fn = [$ \x -> x ] )

          trigger $[lbl]_global_barrier : () = \_ -> (
            ( print "Join done." ;
              $[next]
            ) @OnCounter(id=[# $[lbl]_join_done], eq=[$ $[nodes].size()], reset=[$ false], profile=[$ false])
          )
        }
}
