include "Annotation/Collection.k3"
include "Annotation/Map.k3"
include "Core/Barrier.k3"
include "Core/Builtins.k3"
include "Core/Messaging.k3"

control DistributedCollectionStatistics [ lbl         : label
                                        , query_cl    : [{cl:label, ce:expr}]
                                        , coordinator : expr
                                        , nodes       : expr
                                        , next        : expr ]
{
  ?e => $[lbl]_get_cstats(); $.[e]
     +> {
          // Statistics data structure populated at the coordinator.
          // Key is bucket address, value is bucket size.
          declare $[lbl]_cstats : mut collection {key: address, value: $[|
            -- This metaprogram creates a K3 record type using the list of collection labels.
            -- Each field is an integer type, to store the number of keys in the distributed collection.
            -- {<clbl 1> : int, <clbl 2> : int}
            let recErr _ = error "Invalid collection statistics type record" in
            let sizeFieldLT cRec = spliceRecordField cRec "cl" >>= idOfSLabel >>= \clbl -> return (clbl,TC.int)
            in maybe (recErr ()) (SType . TC.record) (elemsOfSList 'query_cl >>= mapM sizeFieldLT)
          |]} @Map

          // Use this method to gather collection statistics at the coordinator.
          declare $[lbl]_get_cstats : () -> () = \_ -> (
            $[nodes].iterate (\p -> ($[lbl]_collect_cstats, p.addr) <- ())
          )

          // Worker-side trigger to respond to statistics queries.
          trigger $[lbl]_collect_cstats : () = \_ -> (
            ($[lbl]_node_cstats, $[coordinator]) <- (me, $[|
              -- This metaprogram creates a record expression that contains fields
              -- populated with all of the desired collection sizes.
              let recErr _ = error "Invalid collection statistics record expr" in
              let sizeFieldLE cRec = do { l <- (spliceRecordField cRec "cl" >>= idOfSLabel);
                                          e <- (spliceRecordField cRec "ce" >>= expOfSExpr);
                                          return (l, EC.applyMany (EC.project "size" e) [EC.unit]) }
              in maybe (recErr ()) (SExpr . EC.record) (elemsOfSList 'query_cl >>= mapM sizeFieldLE)
            |])
          )

          // Coordinator-side trigger to accumulate collection statistics returns.
          // It prints the bucket distribution when all nodes are done reporting.
          trigger $[lbl]_node_cstats : (address, $[|
            -- This is the same K3 record constructor metaprogram as above.
            -- We could provide a common context of splice values in control annotation rewrites
            -- or support proper arbitrary nesting of Haskell/K3 metaprograms with a K3 quasiquoter.
            let recErr _ = error "Invalid collection statistics type record" in
            let sizeFieldLT cRec = spliceRecordField cRec "cl" >>= idOfSLabel >>= \clbl -> return (clbl,TC.int)
            in maybe (recErr ()) (SType . TC.record) (elemsOfSList 'query_cl >>= mapM sizeFieldLT)
          |])
          = \ns -> (
            (bind ns as (bucket_addr, cbucket_sizes) in
              $[lbl]_cstats.insert {key: bucket_addr, value: cbucket_sizes});
            ( print ($[|exprLabel 'lbl|] ++ " buckets: " ++
                      ($[lbl]_cstats.fold (\acc -> \r -> (acc ++ atos(r.key) ++ " => " ++ $[|
                      -- This metaprogram flattens all collection sizes into a K3 string expression.
                      let strError _ = error "Invalid collection statistics report" in
                      let sizeStr flbl = EC.applyMany (EC.variable "itos")
                                           [EC.project flbl $ EC.project "value" $ EC.variable "r"] in
                      let reportStr acc cRec = do { clbl <- spliceRecordField cRec "cl" >>= idOfSLabel;
                                                    return $ EC.binop OConcat acc
                                                           $ EC.binop OConcat (sizeStr clbl)
                                                           $ EC.constant (CString " ") }
                      in
                      let repExpr cRecs = foldM reportStr (EC.constant (CString "")) cRecs in
                      maybe (strError ()) SExpr $ (elemsOfSList 'query_cl >>= repExpr)
                      |] ++ "\\n"
                      )) ""));
              $[next]
            ) @OnCounter(id=[# $[lbl]_cstats_done], eq=[$ $[nodes].size()], reset=[$ false], profile=[$ false])
          )
        }
}

// Distributed Group By Implementation
// Enabling profiling will display the total elapsed time for the operator

control DistributedGroupByGeneric [ lbl             : label
                                  , peer_next       : expr
                                  , next            : expr
                                  , merge           : expr
                                  , coordinator     : expr
                                  , nodes           : expr
                                  , profile         : expr ]
{
  ignore ( (?e.groupBy ?groupF ?aggF ?accE) : collection ?t )
     => (if $[profile]
          then (() @:StartTimer) @Time(lbl=[# $[lbl]_GROUPBY], tag=[$ "Time "])
          else ()
        );
        $[nodes].iterate (\p -> ($[lbl]_scan, p.addr) <- ())
     +> {
          trigger $[lbl]_scan : () = \_ -> (
            (ignore ( ($.[e].groupBy $.[groupF] $.[aggF] $.[accE])
                            .fold    (\acc -> \v -> ((acc.insert v); acc))
                                     (empty $::[t] @Map)
            ) @SendPartitionByKey( dest_trg      = [$ $[lbl]_merge]
                                 , barrier_trg   = [$ $[lbl]_peer_barrier]
                                 , nodes         = nodes
                                 , send_extra_fn = [$ (\x -> x)]))
          )

          trigger $[lbl]_merge : collection $::[t] @Map = \partials -> (
            partials.iterate (\w -> $[merge] w)
          )

          trigger $[lbl]_peer_barrier : () = \_ -> (
            ( $[peer_next] ;
              ( $[lbl]_global_barrier, $[coordinator] ) <- ()
            ) @OnCounter(id=[# $[lbl]_peer_done], eq=[$ $[nodes].size()], reset=[$ false], profile=[$ false])
          )

          trigger $[lbl]_global_barrier : () = \_ -> (
            ((if $[profile]
              then (() @:StopTimer) @Time(lbl=[# $[lbl]_GROUPBY ], tag=[$ "Time "])
              else ()
            );
            $[next]
            ) @OnCounter(id=[# $[lbl]_done], eq=[$ $[nodes].size()], reset=[$ false], profile=[$ false])
          )
        }
}

control DistributedGroupBy [ lbl             : label
                           , peer_next       : expr
                           , next            : expr
                           , merge           : expr
                           , coordinator     : expr
                           , nodes           : expr
                           , profile         : expr ]
{
  ignore ( (?e.groupBy ?groupF ?aggF ?accE) : collection ?t )
     => (ignore ($.[e].groupBy $.[groupF] $.[aggF] $.[accE]))
          @DistributedGroupByGeneric(
              lbl         = lbl
            , peer_next   = [$ $[peer_next] $[lbl]_result ]
            , next        = next
            , merge       = [$ (\v ->
                                  $[lbl]_result.insert_with v (\a -> \b ->
                                    {key:a.key, value: $[merge] a.value b.value}))
                            ]
            , coordinator = coordinator
            , nodes       = nodes
            , profile     = [$ $[profile] ] )

     +> { declare $[lbl]_result : mut collection $::[t] @Map }
}


control DistributedHashJoin [ lbl             : label
                            , lhs_query       : expr
                            , rhs_query       : expr
                            , lhs_build_merge : expr
                            , rhs_probe_merge : expr
                            , peer_next       : expr
                            , next            : expr
                            , coordinator     : expr
                            , nodes           : expr
                            , lhs_build_ty    : type
                            , rhs_probe_ty    : type
                            , profile         : expr
                            ]
{
  () => (if $[profile]
          then (() @:StartTimer) @Time(lbl=[# $[lbl]_HASHJOIN ], tag=[$ "Time "])
          else ()
        );
        $[nodes].iterate (\p -> ($[lbl]_lhs_scan, p.addr) <- ())
     +> {
        trigger $[lbl]_lhs_scan : () = \_ -> (
          (ignore
            ( $[lhs_query]
            ) @SendPartitionByKey( dest_trg      = [$ $[lbl]_build_lhs]
                                 , barrier_trg   = [$ $[lbl]_lhs_peer_barrier]
                                 , nodes         = nodes
                                 , send_extra_fn = [$ (\x -> x)]))
        )

        trigger $[lbl]_build_lhs : $[lhs_build_ty] = \vals -> (
          vals.iterate $[lhs_build_merge]
        )

        trigger $[lbl]_lhs_peer_barrier : () = \_ -> (
          ( $[nodes].iterate (\p -> ($[lbl]_rhs_scan, p.addr) <- ())
          ) @OnCounter(id=[# $[lbl]_peer_build_done], eq=[$ $[nodes].size()], reset=[$ false], profile=[$ false])
        )

        trigger $[lbl]_rhs_scan : () = \_ -> (
          (( ignore
              ( $[rhs_query]
              ) @SendPartitionByKey( dest_trg      = [$ $[lbl]_probe_rhs]
                                   , barrier_trg   = [$ $[lbl]_rhs_peer_barrier]
                                   , nodes         = nodes
                                   , send_extra_fn = [$ (\x -> x)]))
          ) @OnCounter(id=[# $[lbl]_lhs_done], eq=[$ $[nodes].size()], reset=[$ false], profile=[$ false])
        )

        trigger $[lbl]_probe_rhs : $[rhs_probe_ty] = \vals -> (
          // Probe LHS hash table.
          vals.iterate $[rhs_probe_merge]
        )

        trigger $[lbl]_rhs_peer_barrier : () = \_ -> (
          ( $[peer_next] ;
            ($[lbl]_global_barrier, $[coordinator]) <- ()
          ) @OnCounter(id=[# $[lbl]_rhs_done], eq=[$ $[nodes].size()], reset=[$ false], profile=[$ false])
        )

        trigger $[lbl]_global_barrier : () = \_ -> (
          ( (if $[profile]
               then (() @:StopTimer) @Time(lbl=[# $[lbl]_HASHJOIN ], tag=[$ "Time "])
               else ()
            );
            $[next]
          ) @OnCounter(id=[# $[lbl]_join_done], eq=[$ $[nodes].size()], reset=[$ false], profile=[$ false])
        )
     }
}

control PipelinedBroadcastJoin [ lbl                 : label
                               , lhs_query           : expr
                               , rhs_query           : expr
                               , lhs_probe           : expr
                               , lhs_clear           : expr
                               , broadcast_ty        : type
                               , empty_out_buffer    : expr
                               , pipeline_next       : expr
                               , peer_next           : expr
                               , next                : expr
                               , coordinator         : expr
                               , nodes               : expr]
{
  () => $[nodes].iterate (\p -> ($[lbl]_broadcast, p.addr) <- ())
     +> {
          // Compute any LHS data structures needed for join, then start broadcast.
          trigger $[lbl]_broadcast : () = \_ -> (
            $[lhs_query];
            ( ignore ( $[rhs_query]
            ) @SendBroadcast( dest_trg      = [$ $[lbl]_probe ]
                            , barrier_trg   = [$ $[lbl]_peer_broadcast_barrier ]
                            , nodes         = nodes
                            , send_extra_fn = [$ (\x -> x) ]))
          )

          // Process broadcasted partition from a peer, and pipeline its outputs.
          trigger $[lbl]_probe : $[broadcast_ty] = \vals -> (
            let outputs = vals.fold $[lhs_probe] $[empty_out_buffer] in
            $[pipeline_next] outputs
          )

          trigger $[lbl]_peer_broadcast_barrier : () = \_ -> (
            print "Broadcast join peer finished processing." ;
            (
              $[lhs_clear];
              $[peer_next];
              ($[lbl]_global_barrier, $[coordinator]) <- ()
            ) @OnCounter(id=[# $[lbl]_peer_broadcast_done], eq=[$ $[nodes].size()], reset=[$ false], profile=[$ false])
          )

          trigger $[lbl]_global_barrier : () = \_ -> (
            ( print "Broadcast join done." ;
              $[next]
            ) @OnCounter(id=[# $[lbl]_join_done], eq=[$ $[nodes].size()], reset=[$ false], profile=[$ false])
          )
        }
}

control PipelineSymmetricHashJoin [ lbl                  : label
                                  , lhs_query            : expr
                                  , rhs_query            : expr
                                  , lhs_ht_ty            : type
                                  , rhs_ht_ty            : type
                                  , lhs_probe            : expr
                                  , rhs_probe            : expr
                                  , lhs_insert_with      : expr
                                  , rhs_insert_with      : expr
                                  , empty_out_buffer     : expr
                                  , lhs_pipeline_next    : expr
                                  , rhs_pipeline_next    : expr
                                  , peer_next            : expr
                                  , next                 : expr
                                  , coordinator          : expr
                                  , nodes                : expr
                                  ]
{
  () => $[nodes].iterate (\p -> ($[lbl]_redistribute, p.addr) <- ())
     +> {
          declare $[lbl]_lhs_ht : collection $[lhs_ht_ty] @Map
          declare $[lbl]_rhs_ht : collection $[rhs_ht_ty] @Map
          declare $[lbl]_lhs_done : mut bool = false
          declare $[lbl]_rhs_done : mut bool = false

          trigger $[lbl]_redistribute : () = \_ -> (
            (ignore
              ( $[lhs_query]
              ) @SendPartitionByKey( dest_trg      = [$ $[lbl]_process_redistribute]
                                   , barrier_trg   = [$ $[lbl]_lhs_peer_barrier]
                                   , nodes         = nodes
                                   , send_extra_fn = [$ (\x -> (Some x, None immut, true))]));
            (ignore
              ( $[rhs_query]
              ) @SendPartitionByKey( dest_trg      = [$ $[lbl]_process_redistribute]
                                   , barrier_trg   = [$ $[lbl]_rhs_peer_barrier]
                                   , nodes         = nodes
                                   , send_extra_fn = [$ (\x -> (None immut, Some x, false))]))
          )

          trigger $[lbl]_process_redistribute : ( option (collection $[lhs_ht_ty] @Map)
                                                , option (collection $[rhs_ht_ty] @Map)
                                                , bool)
          = \rd -> (
            bind rd as (lv_opt, rv_opt, is_left) in (
              // Three stages: join other, pipeline outputs, track for other
              if is_left then (
                case lv_opt of
                { Some lvals ->
                  let outputs = lvals.fold ($[rhs_probe] $[lbl]_rhs_ht) $[empty_out_buffer] in
                  ((if outputs.size () > 0 then ( $[lhs_pipeline_next] outputs ) else ());
                    if $[lbl]_rhs_done then () else ( lvals.iterate (\lkv -> $[lbl]_lhs_ht.insert_with lkv $[lhs_insert_with]) ))
                }
                { None -> error (print ($[|exprLabel 'lbl|] ++ "_process_redistribute: invalid left join inputs.")) }
              ) else (
                case rv_opt of
                { Some rvals ->
                  let outputs = rvals.fold ($[lhs_probe] $[lbl]_lhs_ht) $[empty_out_buffer] in
                  ((if outputs.size() > 0 then ( $[rhs_pipeline_next] outputs ) else ());
                    if $[lbl]_lhs_done then () else ( rvals.iterate (\rkv -> $[lbl]_rhs_ht.insert_with rkv $[rhs_insert_with]) ))
                }
                { None -> error (print ($[|exprLabel 'lbl|] ++ "_process_redistribute: invalid right join inputs.")) }
              )
            )
          )

          trigger $[lbl]_lhs_peer_barrier : () = \_ -> (
            (
              // LHS is finished, we no longer need to build/probe the RHS
              $[lbl]_lhs_done = true;
              // TODO: add collection method: $[lbl]_rhs_ht.clear();
              if not $[lbl]_rhs_done then () else (
                $[peer_next];
                ($[lbl]_global_barrier, $[coordinator]) <- ()
              )
            ) @OnCounter(id=[# $[lbl]_peer_lbuild_done], eq=[$ $[nodes].size()], reset=[$ false], profile=[$ false])
          )

          trigger $[lbl]_rhs_peer_barrier : () = \_ -> (
            (
              // RHS is finished, we no longer need to build/probe the LHS
              $[lbl]_rhs_done = true;
              // TODO: add collection method: $[lbl]_lhs_ht.clear();
              if not $[lbl]_lhs_done then () else (
                $[peer_next];
                ($[lbl]_global_barrier, $[coordinator]) <- ()
              )
            ) @OnCounter(id=[# $[lbl]_peer_rbuild_done], eq=[$ $[nodes].size()], reset=[$ false], profile=[$ false])
          )

          trigger $[lbl]_global_barrier : () = \_ -> (
            ( $[next]
            ) @OnCounter(id=[# $[lbl]_join_done], eq=[$ $[nodes].size()], reset=[$ false], profile=[$ false])
          )
        }
}


control SkewShuffle [ lbl             : label
                    , lhs             : expr
                    , skewed_keys     : expr
                    , query           : expr
                    , query_result_ty : type
                    , dest_trg        : expr
                    , barrier_trg     : expr
                    , nodes           : expr
                    , send_extra_fn   : expr
                    ]
{
  () =>
      // Three-component join parts of: round-robin, hash-based and replicated map distribution.
      let part = empty $[query_result_ty] @Map in

      let acc_parts = \acc -> \r -> (
        bind acc as (rr_c, redist_c, repl_c) in
        case $[skewed_keys].lookup {key: r.key, value: false} of
        { Some skew_r ->
            ((if from_left then ( if $[lhs] then rr_c.insert   r else repl_c.insert r )
                           else ( if $[lhs] then repl_c.insert r else rr_c.insert   r ));
             (rr_c, redist_c, repl_c)) }
        { None -> ((redist_c.insert r); (rr_c, redist_c, repl_c)) })
      in

      let skew_parts = $[query].fold acc_parts (part, part, part) in

      // TODO: combine three components per destination peer.
      (bind skew_parts as (rr, redist, repl) in
        ( ignore (rr)     @SendRoundRobin     ( dest_trg      = dest_trg
                                              , barrier_trg   = barrier_trg
                                              , nodes         = nodes
                                              , send_extra_fn = send_extra_fn ) );

        ( ignore (redist) @SendPartitionByKey ( dest_trg      = dest_trg
                                              , barrier_trg   = barrier_trg
                                              , nodes         = nodes
                                              , send_extra_fn = send_extra_fn ) );

        ( ignore (repl)   @SendBroadcast      ( dest_trg      = dest_trg
                                              , barrier_trg   = barrier_trg
                                              , nodes         = nodes
                                              , send_extra_fn = send_extra_fn ) ))
}

control PipelineSkewJoin [ lbl                  : label
                         , lhs_sample_query     : expr
                         , rhs_sample_query     : expr
                         , lhs_query            : expr
                         , rhs_query            : expr
                         , join_key_ty          : type
                         , lhs_ht_ty            : type
                         , rhs_ht_ty            : type
                         , lhs_probe            : expr
                         , rhs_probe            : expr
                         , lhs_insert_ht_with   : expr
                         , rhs_insert_ht_with   : expr
                         , empty_out_buffer     : expr
                         , lhs_pipeline_next    : expr
                         , rhs_pipeline_next    : expr
                         , peer_next            : expr
                         , next                 : expr
                         , coordinator          : expr
                         , nodes                : expr
                         ]
{
    () => $[nodes].iterate (\p -> ($[lbl]_scan, p.addr) <- ())
     +> {
          // Algorithm:
          // Phase 1: collect statistics per peer
          // a. sample each partition, communicate to coordinator
          // b. populate pair counts, and filter extreme values for either pair element based on threshold.
          // c. distribute list of extreme values and source to peers.
          //
          // Phase 2: peer post-query phase
          // each data structure below is a key -> (value collection) mapping support duplicates
          // for each tuple in each side:
          //   if tuple is skewed: add to replicate or round-robin data structure based on source
          //   otherwise add to redistribute data structure
          // send out replicated, round-robin, and redistributed data structures
          //
          // Phase 3: peer receive phase
          // standard pipelined symmetric hashtable build/probe for all (i.e., repl/rr/redistributed) inputs

          // K * c_r / c_x, where K = # nodes, c_r = redist or repl cost, c_x = transfer cost
          declare cost_ratio : real = 16 * 10.0

          // Join key histogram, storing frequency in both LHS and RHS relations.
          declare $[lbl]_hist : collection {key : $[join_key_ty], value : (int, int)} @Map

          declare $[lbl]_lhs_ht : collection $[lhs_ht_ty] @Map
          declare $[lbl]_rhs_ht : collection $[rhs_ht_ty] @Map

          declare $[lbl]_lhs_done : mut bool = false
          declare $[lbl]_rhs_done : mut bool = false

          declare $[lbl]_hist_merge :    {key: $[join_key_ty], value: (int, int)}
                                      -> {key: $[join_key_ty], value: (int, int)}
                                      -> {key: $[join_key_ty], value: (int, int)}
          = \a -> (\b ->
              bind a.value as (alf, arf) in
              bind b.value as (blf, brf) in
              {key: a.key, value: (alf + blf, arf + brf)})

          declare $[lbl]_acc_hifreq :   (collection {key: $[join_key_ty], value: bool} @Map)
                                     -> {key: $[join_key_ty], value: (int, int)}
                                     -> (collection {key: $[join_key_ty], value: bool} @Map)
          = \acc -> (\r ->
              bind r.value as (lfreq, rfreq) in
              let lsource = lfreq > rfreq in
              let maxfreq = if lfreq > rfreq then lfreq else rfreq in
              if maxfreq > cost_ratio then ((acc.insert {key: r.key, value: lsource}; acc))
                                      else acc)

          trigger $[lbl]_peer_sample : () = \_ -> (
            (($[lbl]_process_sample, $[coordinator]) <- ($[lhs_sample_query], true));
            (($[lbl]_process_sample, $[coordinator]) <- ($[rhs_sample_query], false));
            (($[lbl]_peer_sample_barrier, $[coordinator]) <- ())
          )

          trigger $[lbl]_process_sample : ( collection {key: $[join_key_ty], value: int} @Map, bool )
          = \slr -> (
            bind slr as (sampled_keys, from_left) in (
              (sampled_keys.iterate (\i ->
                let nvalue = if from_left then {key: i.key, value: (i.value, 0)}
                                          else {key: i.key, value: (0, i.value)}
                in $[lbl]_hist.insert_with nvalue $[lbl]_hist_merge))
            )
          )

          trigger $[lbl]_peer_sample_barrier : () = \_ -> (
            (
              // Compute high-frequency values
              let skewed = $[lbl]_hist.fold $[lbl]_acc_hifreq (empty {key: $[join_key_ty], value: bool} @Map)
              in (
                // Broadcast skewed values back to nodes.
                $[nodes].iterate (\n -> ($[lbl]_redistribute, n.addr) <- skewed )
              )
            ) @OnCounter(id=[# $[lbl]_peer_sample_done], eq=[$ $[nodes].size()], reset=[$ false], profile=[$ false])
          )

          trigger $[lbl]_redistribute : collection {key: $[join_key_ty], value: bool} @Map =
          \skewed_keys -> (
            () @SkewShuffle( lbl           = lbl
                           , lhs           = [$ true]
                           , skewed_keys   = [$ skewed_keys]
                           , query         = lhs_query
                           , ty            = lhs_ht_ty
                           , dest_trg      = [$ $[lbl]_process_redistribute ]
                           , barrier_trg   = [$ $[lbl]_lhs_peer_barrier ]
                           , nodes         = nodes
                           , send_extra_fn = [$ (\x -> (Some x, None immut, true)) ]) ;

            () @SkewShuffle( lbl           = lbl
                           , lhs           = [$ false]
                           , skewed_keys   = [$ skewed_keys]
                           , query         = rhs_query
                           , ty            = rhs_ht_ty
                           , dest_trg      = [$ $[lbl]_process_redistribute ]
                           , barrier_trg   = [$ $[lbl]_rhs_peer_barrier ]
                           , nodes         = nodes
                           , send_extra_fn = [$ (\x -> (None immut, Some x, false)) ])
          )


          trigger $[lbl]_process_redistribute : ( option (collection $[lhs_ht_ty] @Map)
                                                , option (collection $[rhs_ht_ty] @Map)
                                                , bool )
          = \rd -> (
            bind rd as (lv_opt, rv_opt, is_left) in (
              // Three stages: join other, pipeline outputs, track for other
              if is_left then (
                case lv_opt of
                { Some lvals ->
                  let outputs = lvals.fold $[rhs_probe] $[rhs_empty_out_buffer] in
                  ((if outputs.size () > 0 then $[lhs_pipeline_next] outputs else ());
                    if $[lbl]_rhs_done then () else ( lvals.iterate (\lkv -> $[lbl]_lhs_ht.insert_with lkv $[lhs_insert_with]) ))
                }
                { None -> error (print ($[|exprLabel 'lbl|] ++ "_process_redistribute: invalid left join inputs.")) }
              ) else (
                case rv_opt of
                { Some rvals ->
                  let outputs = rvals.fold $[lhs_probe] $[lhs_empty_out_buffer] in
                  ((if outputs.size() > 0 then $[rhs_pipeline_next] outputs else ());
                    if $[lbl]_lhs_done then () else ( rvals.iterate (\rkv -> $[lbl]_rhs_ht.insert_with rkv $[rhs_insert_with]) ))
                }
                { None -> error (print ($[|exprLabel 'lbl|] ++ "_process_redistribute: invalid right join inputs.")) }
              )
            )
          )

          trigger $[lbl]_lhs_peer_barrier : () = \_ -> (
            print "Skew join LHS finished processing." ;
            (
              // LHS is finished, we no longer need to build/probe the RHS
              $[lbl]_lhs_done = true;
              // TODO: add collection method: $[lbl]_rhs_ht.clear();
              if not $[lbl]_rhs_done then () else (
                $[peer_next];
                ($[lbl]_global_barrier, $[coordinator]) <- ()
              )
            ) @OnCounter(id=[# $[lbl]_peer_lbuild_done], eq=[$ $[nodes].size()], reset=[$ false], profile=[$ false])
          )

          trigger $[lbl]_rhs_peer_barrier : () = \_ -> (
            print "Skew join RHS finished processing." ;
            (
              // RHS is finished, we no longer need to build/probe the LHS
              $[lbl]_rhs_done = true;
              // TODO: add collection method: $[lbl]_lhs_ht.clear();
              if not $[lbl]_lhs_done then () else (
                $[peer_next];
                ($[lbl]_global_barrier, $[coordinator]) <- ()
              )
            ) @OnCounter(id=[# $[lbl]_peer_rbuild_done], eq=[$ $[nodes].size()], reset=[$ false], profile=[$ false])
          )

          trigger $[lbl]_global_barrier : () = \_ -> (
            ( print "Skew join done." ;
              $[next]
            ) @OnCounter(id=[# $[lbl]_join_done], eq=[$ $[nodes].size()], reset=[$ false], profile=[$ false])
          )
        }
}
