include "Annotation/Collection.k3"
include "Annotation/Map.k3"
include "Annotation/BulkFlatCollection.k3"
include "Core/Barrier.k3"
include "Core/Builtins.k3"
include "Core/MachineMessaging.k3"

control SQL {
  () => ()
     +> {
      declare index_by_hash : forall a. a -> int = (\s -> (
        let n = workers.size() in
        let h = (hash s) in
        ((h % n) + n) % n
      ))
     }
}

// TODO(jbw) exclude machine master when streaming blocks
control StreamRawFromFile[lbl: label, path: expr, receive_trig: expr, punc_trig: expr] {
  () => (peer_masters.lookup 
                       {key: me, value: me} 
                       (\_ -> error (print "Missing Peer Master")) 
                       (\kv -> if kv.key == kv.value then ($[lbl]_read_start, me) <- () else () )
        )
  +> 
  {
    // TODO(jbw) useExprLabel to give a unique channel id to the file
    trigger $[lbl]_read_start: () = \_ -> (
      openFile me "input" $[path] "raw" false "r";
      ($[lbl]_read_loop, me) <- 0
    ) 

    trigger $[lbl]_read_loop: int = \i -> (
      if hasRead me "input"
      then (
        let a = (local_workers.at i).addr in (
          ($[receive_trig], a) <- doRead me "input";
          ($[lbl]_read_loop, me) <- if i+1 < local_workers.size() then i+1 else 0
        )
      )
      else (
        local_workers.iterate (\p -> ($[punc_trig], p.addr) <- () )
      )
    )
  }
}

// TODO(jbw) (do we need @:Accumulate?, @:HGroupBy
control PartitionByKey2 {
  ?e : collection ?content_t
    => ( ($.[e].group_by)
                 (\v -> index_by_hash v.key)
                 (\acc -> \v -> ((acc.insert v); acc))
                 empty $::[content_t] @Collection )
  +> { }
}

control Shuffle [ dest_trig: expr ] {
  ?e : collection ?content_t
    => $.[e].iterate (\kv -> ($[dest_trig], (workers.at kv.key).addr) <- kv.value)
  +> { }
}

control ShuffleByKey [ dest_trig: expr ] {
  ?e : collection ?content_t
    => ($.[e] @PartitionByKey2) @Shuffle(dest_trig=[$ $[dest_trig]])
  +> { }
}

control Barrier [lbl: label, count: expr] {
  ?e => $[lbl]_count = $[lbl]_count + 1; 
        if $[lbl]_count == $[count]
        then ($[lbl]_count = 0; $.[e])
        else ()

  +> { declare $[lbl]_count : mut int = 0 }
}

// TODO(jbw) figure out how to feed filepath into GroupBy Annotation
// Requires: peers, master
// Assumes: var is a global.
control DistributedGroupBy2[lbl : label, merge : expr]
{
  // Stream version 
  ( (?var = ( ((?e : collection ?origT) @:BaseTable).group_by ?groupF ?aggF ?accE) : collection ?T);
    (?dtrig, ?daddr) <- ()
  )
  => () @StreamRawFromFile(lbl=[# $[lbl]_shuffle], path=[$ "/local/data/batches.in"], receive_trig=[$ $[lbl]_parse_redistribute], punc_trig=[$ $[lbl]_stream_punc])
  +> { declare $[lbl]_next : () -> () = (\_ -> ($.[dtrig], $.[daddr]) <- ()) }
 
  // Batch versions send punctuation immediately after redistrubte
  ( (?var = ( (?e.group_by ?groupF ?aggF ?accE) : collection ?T ) );
    (?dtrig, ?daddr) <- ()
  )
  => ( ($[lbl]_redistribute, me) <- ();
       workers.iterate (\p -> ($[lbl]_punc, p.addr) <- ()) 
     )
  +> { declare $[lbl]_next : () -> () = (\_ -> ($.[dtrig], $.[daddr]) <- ()) }

  ( ?var = ( (?e.group_by ?groupF ?aggF ?accE) : collection ?T ) )
  => ( ($[lbl]_redistribute, me) <- ();
       workers.iterate (\p -> ($[lbl]_redist_punc, p.addr) <- ()) 
     )
  +> { declare $[lbl]_next : () -> () = (\_ -> ()) }

  shared {
    declare $[lbl]_index_by_hash : forall a. a -> int = (\s -> (
        let n = workers.size() in
        let h = (hash s) in
        ((h % n) + n) % n
      ))
    declare $[lbl]_partials : mut collection $::[T] @Map

    trigger $[lbl]_parse_redistribute : string = \s -> (
      let bfc = empty $::[origT] @BulkFlatCollection
      in (
        bfc.load s;
        ignore (bfc.group_by $.[groupF] $.[aggF] $.[accE]) @ShuffleByKey(dest_trig=[$ $[lbl]_merge])
      )
    )

    trigger $[lbl]_redistribute : () = \_ -> (
      ignore ($.[e].group_by $.[groupF] $.[aggF] $.[accE]) @ShuffleByKey(dest_trig=[$ $[lbl]_merge])
    )

    trigger $[lbl]_merge : collection $::[T] @Collection = \partials -> (
      partials.iterate (\kv -> 
        $[lbl]_partials.insert_with
                         kv
                         (\a -> \b -> {key: a.key, value: $[merge] a.value b.value})
      )
    )  
    
    trigger $[lbl]_stream_punc: () = \_ -> (
      workers.iterate (\p -> ($[lbl]_redist_punc, p.addr) <- () )
    )

    trigger $[lbl]_redist_punc: () = \_ -> (
      ( $#[var] = $[lbl]_partials.fold (\acc -> \e -> ((acc.insert e); acc)) empty $::[T] @Collection);
      ( print ($[|exprLabel 'lbl|] ++ " " ++ atos me ++ " peer group-by done") );
      ( $[lbl]_next () );
      ( $[lbl]_global_barrier, master ) <- ()
    ) @Barrier(lbl=[# $[lbl]_punc], count=[$ workers.size() ])

    trigger $[lbl]_global_barrier : () = \_ -> (
      ( print ($[|exprLabel 'lbl|] ++ " group-by done")
      ) @Barrier(lbl=[# $[lbl]_done], count=[$ workers.size() ])
    )
  }
}

// Requires: peers, master
// Assumes: var is a global.
control DistributedHashJoin2 [ lbl : label ]
{
  ( (?var = (( ?lqueryE : ?LQueryT ).equijoin ( ?rqueryE : ?RQueryT ) ( ?lkeyE : ?LKeyT ) ( ?rkeyE : ?RKeyT ) ?outputE));
    (?dtrig, ?daddr) <- ()
  )
  => ( ($[lbl]_lhs_redistribute, me) <- () )
  +> { declare $[lbl]_next : () -> () = (\_ -> ($.[dtrig], $.[daddr]) <- ()) }

  ( ?var = (( ?lqueryE : ?LQueryT ).equijoin ( ?rqueryE : ?RQueryT ) ( ?lkeyE : ?LKeyT ) ( ?rkeyE : ?RKeyT ) ?outputE) )
  => ( ($[lbl]_lhs_redistribute, me) <- () )
  +> { declare $[lbl]_next : () -> () = (\_ -> ()) }

  shared {
    declare $[lbl]_lhs_default_tuples : $::[LQueryT]
    declare $[lbl]_rhs_default_tuples : $::[RQueryT]

    declare $[lbl]_lhs_ht : mut $[| equijoinMapType 'LKeyT.typ 'LQueryT.typ |]

    trigger $[lbl]_lhs_redistribute : () = \_ -> (
      (( ignore ( $.[lqueryE].fold (\acc -> \e ->
                                     ((acc.upsert_with {key: $.[lkeyE] e, value: $[lbl]_lhs_default_tuples}
                                         (\_ -> (let r = $[|mkEmpty 'LQueryT.typ|] in (r.insert e; {key: $.[lkeyE] e, value: r})))
                                         (\c -> ((c.value.insert e); {key: c.key, value: c.value}));
                                       acc)))
                                   ($[|equijoinEmptyMap 'LKeyT.typ 'LQueryT.typ|]) ))
         @PartitionShuffleWithMissing(
           lbl           = [# $[lbl]_lhs]
         , dest_trg      = [$ $[lbl]_lhs_process_redistribute]
         , nodes         = [$ peers ]
         , send_extra_fn = [$ \x -> x]
         , send_ty       = [: $[|equijoinMapType 'LKeyT.typ 'LQueryT.typ|] ]
         ))
    )

    trigger $[lbl]_lhs_process_redistribute : $[|equijoinMapType 'LKeyT.typ 'LQueryT.typ|] = (\vals ->
    ((vals.iterate (\lhs_ht_tuple ->
        $[lbl]_lhs_ht.insert_with lhs_ht_tuple
          (\old -> (\new -> {key: old.key, value: old.value.combine new.value}))));
      ( peers.iterate (\p -> ($[lbl]_rhs_redistribute, p.addr) <- ())
      ) @OnCounter(id=[# $[lbl]_peer_build_done], eq=[$ peers.size()], reset=[$ false], profile=[$ false]))
    )

    trigger $[lbl]_rhs_redistribute : () = \_ -> (
      (( ignore ( $.[rqueryE].fold (\acc -> \e ->
                                     ((acc.upsert_with {key: $.[rkeyE] e, value: $[lbl]_rhs_default_tuples}
                                         (\_ -> (let r = $[|mkEmpty 'RQueryT.typ|] in (r.insert e; {key: $.[rkeyE] e, value: r})))
                                         (\c -> ((c.value.insert e); {key: c.key, value: c.value}));
                                       acc)))
                                   ($[|equijoinEmptyMap 'RKeyT.typ 'RQueryT.typ|]) ))
         @PartitionShuffleWithMissing(
           lbl           = [# $[lbl]_rhs]
         , dest_trg      = [$ $[lbl]_rhs_process_redistribute]
         , nodes         = [$ peers]
         , send_extra_fn = [$ \x -> x]
         , send_ty       = [: $[|equijoinMapType 'RKeyT.typ 'RQueryT.typ|] ]
         )
      ) @OnCounter(id=[# $[lbl]_lhs_done], eq=[$ peers.size()], reset=[$ false], profile=[$ false])
    )

    trigger $[lbl]_rhs_process_redistribute : $[|equijoinMapType 'RKeyT.typ 'RQueryT.typ|] = (\vals -> (
      // Probe LHS hash table, and insert matches into materialized result.
      ( vals.iterate (\rhs_ht_tuple ->
          $[lbl]_lhs_ht.lookup {key: rhs_ht_tuple.key, value: $[lbl]_lhs_default_tuples}
            (\_ -> ())
            (\lhs_ht_tuple -> lhs_ht_tuple.value.iterate (\le ->
                rhs_ht_tuple.value.iterate (\re -> $#[var].insert {elem: $.[outputE] le re}))))
      );
      ( ( print ($[|exprLabel 'lbl|] ++ " " ++ atos me ++ " peer equijoin done") );
        ( $[lbl]_lhs_ht = $[|equijoinEmptyMap 'LKeyT.typ 'LQueryT.typ|]);
        ( $[lbl]_next () );
        ( $[lbl]_global_barrier, master ) <- ()
      ) @OnCounter(id=[# $[lbl]_rhs_done], eq=[$ peers.size()], reset=[$ false], profile=[$ false])
      ))

    trigger $[lbl]_global_barrier : () = \_ -> (
      ( print ($[|exprLabel 'lbl|] ++ " equijoin done")
      ) @OnCounter(id=[# $[lbl]_join_done], eq=[$ peers.size()], reset=[$ false], profile=[$ false])
    )
  }
}

// Requires: peers, master, masters, peer_masters
// Assumes: var is a global.
control BroadcastJoin2 [ lbl : label ]
{
  ( (?var = (( ?LQueryE : ?LQueryT ).join ( ?RQueryE : ?RQueryT ) ?matchE ?outputE));
    (?dtrig, ?daddr) <- ()
  )
  => ( ($[lbl]_broadcast, me) <- () )
  +> { declare $[lbl]_next : () -> () = (\_ -> ($.[dtrig], $.[daddr]) <- () ) }

  ( ?var = (( ?LQueryE : ?LQueryT ).join ( ?RQueryE : ?RQueryT ) ?matchE ?outputE) )
  => ( ($[lbl]_broadcast, me) <- () )
  +> { declare $[lbl]_next : () -> () = (\_ -> ()) }

  shared {
    declare $[lbl]_lhs : mut $::[LQueryT]

    // Compute any LHS data structures needed for join, then start broadcast.
    trigger $[lbl]_broadcast : () = \_ -> (
      ( $[| broadcastjoinMaterialize 'lbl 'LQueryE.expr |] );
      ((( ignore $.[RQueryE]
      ) @:Send
      ) @BroadcastByMachine( lbl           = [# $[lbl]_rj_bcast ]
                           , dest_trg      = [$ $[lbl]_probe ]
                           , masters       = [$ masters ]
                           , masters_map   = [$ peer_masters ]
                           , send_ty       = [: $::[RQueryT] ]
                           , send_extra_fn = [$ \x -> x ] )
      )
    )

    // Process broadcasted partition from a peer as they arrive.
    trigger $[lbl]_probe : $::[RQueryT] = ((\vals -> (
      ( ($[| broadcastJoinLHSVar 'lbl 'LQueryE.expr |].join
          vals $.[matchE] $.[outputE]).iterate (\out -> $#[var].insert out) );
      (
        ( print ($[|exprLabel 'lbl|] ++ " peer broadcast join done.") );
        ( $[lbl]_next () );
        ($[lbl]_global_barrier, master) <- ()
      ) @OnCounter(id=[# $[lbl]_peer_broadcast_done], eq=[$ peers.size()], reset=[$ false], profile=[$ false])
    )
    ) @:Receive
    ) @BroadcastByMachine( lbl           = [# $[lbl]_rj_bcast ]
                         , dest_trg      = [$ $[lbl]_probe ]
                         , masters       = [$ masters ]
                         , masters_map   = [$ peer_masters ]
                         , send_ty       = [: $::[RQueryT] ]
                         , send_extra_fn = [$ \x -> x ] )

    trigger $[lbl]_global_barrier : () = \_ -> (
      ( print ($[|exprLabel 'lbl|] ++ " broadcast join done.")
      ) @OnCounter(id=[# $[lbl]_join_done], eq=[$ peers.size()], reset=[$ false], profile=[$ false])
    )
  }
}
