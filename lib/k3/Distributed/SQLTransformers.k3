include "Annotation/Collection.k3"
include "Annotation/Map.k3"
include "Annotation/BulkFlatCollection.k3"
include "Core/Barrier.k3"
include "Core/Builtins.k3"
include "Core/MachineMessaging.k3"

// TODO(jbw) find a good home for index_by_hash
control SQL {
  () => ()
     +> {
      declare index_by_hash : forall a. a -> int = (\s -> (
        let n = workers.size() in
        let h = (hash s) in
        ((h % n) + n) % n
      ))
     }
}

// Read values from the file at the specified path, sending each value to one of the 'workers' by round-robin.
// After the file is exhausted, send punctuation to the specified trigger.
control StreamRawFromFile [ lbl: label, path: expr, receive_trig: expr, punc_trig: expr ] {
  () => ( ($[lbl]_read_start, me) <- () )@IfMachineMaster
  +>
  {
    declare $[lbl]_file_id: string = $[|exprLabel 'lbl|] ++ "_input"

    trigger $[lbl]_read_start: () = \_ -> (
      print ((atos me) ++ ": Opening " ++ $[path]);
      openFile me $[lbl]_file_id $[path] "raw" false "r";
      ($[lbl]_read_loop, me) <- 0
    )

    trigger $[lbl]_read_loop: int = \i -> (
      if hasRead me $[lbl]_file_id
      then (
        ($[receive_trig], (local_workers.at i).addr) <- doRead me $[lbl]_file_id;
        ($[lbl]_read_loop, me) <- if i+1 < local_workers.size() then i+1 else 0
      )
      else (
        print ((atos me) ++ ": Done reading " ++ $[path]);
        local_workers.iterate (\p -> ($[punc_trig], p.addr) <- () )
      )
    )
  }
}

// TODO(jbw) Solve name conflicts: remove the 2.
control PartitionByKey2 {
  ?e : collection ?content_t
    => ( ($.[e].group_by)
                 (\v -> index_by_hash v.key)
                 (\acc -> \v -> ((acc.insert v); acc))
                 empty $::[content_t] @Collection )
  +> { }
}

control Shuffle [ dest_trig: expr ] {
  ?e : collection ?content_t
    => $.[e].iterate (\kv -> ($[dest_trig], (workers.at kv.key).addr) <- kv.value)
  +> { }
}

control ShuffleByKey [ dest_trig: expr ] {
  ?e : collection ?content_t
    => ($.[e] @PartitionByKey2) @Shuffle(dest_trig=[$ $[dest_trig]])
  +> { }
}

control Barrier [ lbl: label, count: expr ] {
  ?e => $[lbl]_count = $[lbl]_count + 1;
        if $[lbl]_count == $[count]
        then ($[lbl]_count = 0; $.[e])
        else ()

  +> { declare $[lbl]_count : mut int = 0 }
}

// TODO(jbw) figure out how to feed filepath into GroupBy Annotation
// TODO(jbw) consider folding into a map after groupby
// Requires: peers, master
// Assumes: var is a global.
control DistributedGroupBy2 [ lbl : label, merge : expr ]
{
  // Block-based version. TODO(jbw) Property name
  ( (?var = (( (((?Expr) : collection ?origT)).group_by ?groupF ?aggF ?accE) @:Stream) : collection ?KVT);
    (?dtrig, ?daddr) <- ()
  )
  => () @StreamRawFromFile( lbl=[# $[lbl]_shuffle]
                          , path=[$ $[lbl]_path]
                          , receive_trig=[$ $[lbl]_parse_redistribute]
                          , punc_trig=[$ $[lbl]_stream_punc]
                          )
  +> { declare $[lbl]_path : string = $[|extractPathBFC 'Expr.expr|]

       declare $[lbl]_next : () -> () = (\_ -> ($.[dtrig], $.[daddr]) <- ())

       // Given a raw string, load it into a BFC. Run the local group_by on the BFC instead of the provided expression.
       trigger $[lbl]_parse_redistribute : string = \s -> (
         let bfc = empty $::[origT] @BulkFlatCollection
         in (
           bfc.load s;
           ignore (($[|baseTableBFC 'Expr.expr (EC.variable "bfc")|]).group_by $.[groupF] $.[aggF] $.[accE]) @ShuffleByKey(dest_trig=[$ $[lbl]_merge])
         )
       )

       // Receive punctuation indicating that the input stream is exhausted
       trigger $[lbl]_stream_punc: () = \_ -> (
         workers.iterate (\p -> ($[lbl]_redist_punc, p.addr) <- () )
       )
     }

  // Batch version (Send punctuation immediately after a single group_by)
  ( (?var = ( ((?Expr : collection ?origT).group_by ?groupF ?aggF ?accE) : collection ?KVT ) );
    (?dtrig, ?daddr) <- ()
  )
  => ( ($[lbl]_redistribute, me) <- ();
       workers.iterate (\p -> ($[lbl]_redist_punc, p.addr) <- ())
     )
  +> { declare $[lbl]_next : () -> () = (\_ -> ($.[dtrig], $.[daddr]) <- ()) }

  ( ?var = ( ((?Expr : collection ?origT).group_by ?groupF ?aggF ?accE) : collection ?KVT ) )
  => ( ($[lbl]_redistribute, me) <- ();
       workers.iterate (\p -> ($[lbl]_redist_punc, p.addr) <- ())
     )
  +> { declare $[lbl]_next : () -> () = (\_ -> ()) }

  shared {
    declare $[lbl]_partials : mut collection $::[KVT] @Map

    // Run a local group_by directly on the provided expression
    trigger $[lbl]_redistribute : () = \_ -> (
      ignore ($.[Expr].group_by $.[groupF] $.[aggF] $.[accE]) @ShuffleByKey(dest_trig=[$ $[lbl]_merge])
    )

    // Merge partial aggregates into global state
    trigger $[lbl]_merge : collection $::[KVT] @Collection = \partials -> (
      partials.iterate (\kv ->
        $[lbl]_partials.insert_with
                         kv
                         (\a -> \b -> {key: a.key, value: $[merge] a.value b.value})
      )
    )

    // Receive punctuation indicating that a worker is done sending partial aggregates
    trigger $[lbl]_redist_punc: () = \_ -> (
      ( $#[var] = $[lbl]_partials.fold (\acc -> \e -> ((acc.insert e); acc)) empty $::[KVT] @Collection);
      ( print ($[|exprLabel 'lbl|] ++ " " ++ atos me ++ " worker group-by done") );
      ( $[lbl]_next () )
    ) @Barrier(lbl=[# $[lbl]_punc], count=[$ workers.size() ])
  }
}

// Requires: peers, master
// Assumes: var is a global.
control DistributedHashJoin2 [ lbl : label ]
{
  ( (?var = (( ?lqueryE : ?LQueryT ).equijoin ( ?rqueryE : ?RQueryT ) ( ?lkeyE : ?LKeyT ) ( ?rkeyE : ?RKeyT ) ?outputE));
    (?dtrig, ?daddr) <- ()
  )
  => ( ($[lbl]_lhs_redistribute, me) <- () )
  +> { declare $[lbl]_next : () -> () = (\_ -> ($.[dtrig], $.[daddr]) <- ()) }

  ( ?var = (( ?lqueryE : ?LQueryT ).equijoin ( ?rqueryE : ?RQueryT ) ( ?lkeyE : ?LKeyT ) ( ?rkeyE : ?RKeyT ) ?outputE) )
  => ( ($[lbl]_lhs_redistribute, me) <- () )
  +> { declare $[lbl]_next : () -> () = (\_ -> ()) }

  shared {
    declare $[lbl]_lhs_default_tuples : $::[LQueryT]
    declare $[lbl]_rhs_default_tuples : $::[RQueryT]

    declare $[lbl]_lhs_ht : mut $[| equijoinMapType 'LKeyT.typ 'LQueryT.typ |]

    trigger $[lbl]_lhs_redistribute : () = \_ -> (
      (( ignore ( $.[lqueryE].fold (\acc -> \e ->
                                     ((acc.upsert_with {key: $.[lkeyE] e, value: $[lbl]_lhs_default_tuples}
                                         (\_ -> (let r = $[|mkEmpty 'LQueryT.typ|] in (r.insert e; {key: $.[lkeyE] e, value: r})))
                                         (\c -> ((c.value.insert e); {key: c.key, value: c.value}));
                                       acc)))
                                   ($[|equijoinEmptyMap 'LKeyT.typ 'LQueryT.typ|]) ))
         @PartitionShuffleWithMissing(
           lbl           = [# $[lbl]_lhs]
         , dest_trg      = [$ $[lbl]_lhs_process_redistribute]
         , nodes         = [$ peers ]
         , send_extra_fn = [$ \x -> x]
         , send_ty       = [: $[|equijoinMapType 'LKeyT.typ 'LQueryT.typ|] ]
         ))
    )

    trigger $[lbl]_lhs_process_redistribute : $[|equijoinMapType 'LKeyT.typ 'LQueryT.typ|] = (\vals ->
    ((vals.iterate (\lhs_ht_tuple ->
        $[lbl]_lhs_ht.insert_with lhs_ht_tuple
          (\old -> (\new -> {key: old.key, value: old.value.combine new.value}))));
      ( peers.iterate (\p -> ($[lbl]_rhs_redistribute, p.addr) <- ())
      ) @OnCounter(id=[# $[lbl]_peer_build_done], eq=[$ peers.size()], reset=[$ false], profile=[$ false]))
    )

    trigger $[lbl]_rhs_redistribute : () = \_ -> (
      (( ignore ( $.[rqueryE].fold (\acc -> \e ->
                                     ((acc.upsert_with {key: $.[rkeyE] e, value: $[lbl]_rhs_default_tuples}
                                         (\_ -> (let r = $[|mkEmpty 'RQueryT.typ|] in (r.insert e; {key: $.[rkeyE] e, value: r})))
                                         (\c -> ((c.value.insert e); {key: c.key, value: c.value}));
                                       acc)))
                                   ($[|equijoinEmptyMap 'RKeyT.typ 'RQueryT.typ|]) ))
         @PartitionShuffleWithMissing(
           lbl           = [# $[lbl]_rhs]
         , dest_trg      = [$ $[lbl]_rhs_process_redistribute]
         , nodes         = [$ peers]
         , send_extra_fn = [$ \x -> x]
         , send_ty       = [: $[|equijoinMapType 'RKeyT.typ 'RQueryT.typ|] ]
         )
      ) @OnCounter(id=[# $[lbl]_lhs_done], eq=[$ peers.size()], reset=[$ false], profile=[$ false])
    )

    trigger $[lbl]_rhs_process_redistribute : $[|equijoinMapType 'RKeyT.typ 'RQueryT.typ|] = (\vals -> (
      // Probe LHS hash table, and insert matches into materialized result.
      ( vals.iterate (\rhs_ht_tuple ->
          $[lbl]_lhs_ht.lookup {key: rhs_ht_tuple.key, value: $[lbl]_lhs_default_tuples}
            (\_ -> ())
            (\lhs_ht_tuple -> lhs_ht_tuple.value.iterate (\le ->
                rhs_ht_tuple.value.iterate (\re -> $#[var].insert {elem: $.[outputE] le re}))))
      );
      ( ( print ($[|exprLabel 'lbl|] ++ " " ++ atos me ++ " peer equijoin done") );
        ( $[lbl]_lhs_ht = $[|equijoinEmptyMap 'LKeyT.typ 'LQueryT.typ|]);
        ( $[lbl]_next () );
        ( $[lbl]_global_barrier, master ) <- ()
      ) @OnCounter(id=[# $[lbl]_rhs_done], eq=[$ peers.size()], reset=[$ false], profile=[$ false])
      ))

    trigger $[lbl]_global_barrier : () = \_ -> (
      ( print ($[|exprLabel 'lbl|] ++ " equijoin done")
      ) @OnCounter(id=[# $[lbl]_join_done], eq=[$ peers.size()], reset=[$ false], profile=[$ false])
    )
  }
}

// Requires: peers, master, masters, peer_masters
// Assumes: var is a global.
control BroadcastJoin2 [ lbl : label ]
{
  ( (?var = (( ?LQueryE : ?LQueryT ).join ( ?RQueryE : ?RQueryT ) ?matchE ?outputE));
    (?dtrig, ?daddr) <- ()
  )
  => ( ($[lbl]_broadcast, me) <- () )
  +> { declare $[lbl]_next : () -> () = (\_ -> ($.[dtrig], $.[daddr]) <- () ) }

  ( ?var = (( ?LQueryE : ?LQueryT ).join ( ?RQueryE : ?RQueryT ) ?matchE ?outputE) )
  => ( ($[lbl]_broadcast, me) <- () )
  +> { declare $[lbl]_next : () -> () = (\_ -> ()) }

  shared {
    declare $[lbl]_lhs : mut $::[LQueryT]

    // Compute any LHS data structures needed for join, then start broadcast.
    trigger $[lbl]_broadcast : () = \_ -> (
      ( $[| broadcastjoinMaterialize 'lbl 'LQueryE.expr |] );
      ((( ignore $.[RQueryE]
      ) @:Send
      ) @BroadcastByMachine( lbl           = [# $[lbl]_rj_bcast ]
                           , dest_trg      = [$ $[lbl]_probe ]
                           , masters       = [$ masters ]
                           , masters_map   = [$ peer_masters ]
                           , send_ty       = [: $::[RQueryT] ]
                           , send_extra_fn = [$ \x -> x ] )
      )
    )

    // Process broadcasted partition from a peer as they arrive.
    trigger $[lbl]_probe : $::[RQueryT] = ((\vals -> (
      ( ($[| broadcastJoinLHSVar 'lbl 'LQueryE.expr |].join
          vals $.[matchE] $.[outputE]).iterate (\out -> $#[var].insert out) );
      (
        ( print ($[|exprLabel 'lbl|] ++ " peer broadcast join done.") );
        ( $[lbl]_next () );
        ($[lbl]_global_barrier, master) <- ()
      ) @OnCounter(id=[# $[lbl]_peer_broadcast_done], eq=[$ peers.size()], reset=[$ false], profile=[$ false])
    )
    ) @:Receive
    ) @BroadcastByMachine( lbl           = [# $[lbl]_rj_bcast ]
                         , dest_trg      = [$ $[lbl]_probe ]
                         , masters       = [$ masters ]
                         , masters_map   = [$ peer_masters ]
                         , send_ty       = [: $::[RQueryT] ]
                         , send_extra_fn = [$ \x -> x ] )

    trigger $[lbl]_global_barrier : () = \_ -> (
      ( print ($[|exprLabel 'lbl|] ++ " broadcast join done.")
      ) @OnCounter(id=[# $[lbl]_join_done], eq=[$ peers.size()], reset=[$ false], profile=[$ false])
    )
  }
}
